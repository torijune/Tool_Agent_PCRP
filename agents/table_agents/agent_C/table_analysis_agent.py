import os
import openai

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableLambda

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)

TABLE_PROMPT = """
ë‹¹ì‹ ì€ ê°ê´€ì ì¸ í†µê³„ ê¸°ë°˜ ìš”ì•½ì„ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” ë¶„ì„ê°€ì…ë‹ˆë‹¤.

ì„¤ë¬¸ ì¡°ì‚¬ ì§ˆë¬¸: 
{selected_question}

ì•„ë˜ëŠ” ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•œ ì„¤ë¬¸ì¡°ì‚¬ ë°ì´í„°ë¥¼ ì •ë¦¬í•œ í‘œì´ë©°, ê° í–‰ì€ ì¸êµ¬ì§‘ë‹¨(ì˜ˆ: ì„±ë³„, ì—°ë ¹ëŒ€), ê° ì—´ì€ í•´ë‹¹ ì§‘ë‹¨ì˜ ì‘ë‹µ í†µê³„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

ğŸ“Š [í‘œ ë°ì´í„° (ì„ í˜•í™”ëœ í˜•íƒœ)]
{linearized_table}

ğŸ“ˆ [ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ (ëŒ€ë¶„ë¥˜ë³„ í•­ëª©ë³„ max/min ë° ë¶„ì‚° ë“±)]
{numeric_anaylsis}

ğŸ§  Chain of Thought ì¶”ë¡  ìˆœì„œ:
1. ê° í•­ëª©(ì˜ˆ: ê´€ì‹¬ë„ í‰ê· , ê´€ì‹¬ìˆë‹¤ ë¹„ìœ¨ ë“±)ì— ëŒ€í•´ ê·¸ë£¹ ê°„ ìˆ˜ì¹˜ ì°¨ì´ê°€ ëšœë ·í•œì§€ íŒŒì•…í•©ë‹ˆë‹¤.
2. ê·¹ë‹¨ê°’(ìµœê³ /ìµœì € ê·¸ë£¹)ê³¼ í‰ê· , í‘œì¤€í¸ì°¨ ë˜ëŠ” ë²”ìœ„(range)ë¥¼ ë¹„êµí•˜ì—¬ ì˜ë¯¸ ìˆëŠ” ì°¨ì´ë¥¼ ê°€ì§„ ëŒ€ë¶„ë¥˜ ê·¸ë£¹ì„ ìš°ì„ ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
3. ë„ì¶œëœ íŠ¹ì´ì (ì˜ˆ: 60ëŒ€ëŠ” í‰ê·  4.1ë¡œ ê°€ì¥ ë†’ìŒ)ì„ ë°”íƒ•ìœ¼ë¡œ ê°„ê²°í•˜ê³  ê°ê´€ì ì¸ ìš”ì•½ë¬¸ì„ ì‘ì„±í•©ë‹ˆë‹¤.

ğŸ“ ì‘ì„± ì¡°ê±´:
    - ìˆ˜ì¹˜ ê¸°ë°˜ íŠ¹ì§•(ì˜ˆ: í‰ê· , % ì°¨ì´ ë“±)ë§Œì„ ë°”íƒ•ìœ¼ë¡œ í•´ì„í•˜ë©°, ì™¸ë¶€ ë°°ê²½ì§€ì‹ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
    - ëª¨ë“  ì†Œë¶„ë¥˜ë¥¼ ì—´ê±°í•˜ì§€ ë§ˆì„¸ìš”. ë³€ë™í­ì´ í¬ê±°ë‚˜ íŠ¹ì§•ì ì¸ ê·¸ë£¹ë§Œ ì„ íƒì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì„¸ìš”.
    - ë¬¸ì¥ì€ **ê°„ê²°í•˜ê³  ëª…í™•í•˜ë©°**, ì£¼ê´€ì  í‘œí˜„ ì—†ì´ **ê°ê´€ì ì¸ ë¬¸ì²´**ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
    - í•œêµ­ì–´ë¡œ ì„œìˆ í˜• ë‹¨ë½ 1~2ê°œë¡œ êµ¬ì„±ëœ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    - ë³´ê³ ì„œì—ëŠ” ë¬¸ë‹¨ ì œëª© ì—†ì´, ìš”ì•½ ë‚´ìš©ë§Œ í¬í•¨í•©ë‹ˆë‹¤.

ğŸ§¾ ìµœì¢… ì¶œë ¥ ì˜ˆì‹œ (í˜•ì‹):
ëŒ€ê¸°í™˜ê²½ì— ëŒ€í•œ ê´€ì‹¬ë„ëŠ” ì—°ë ¹, ê±´ê°•ìƒíƒœ, ì£¼ìš” ì²´ë¥˜ ê³µê°„ì— ë”°ë¼ ìœ ì˜ë¯¸í•œ ì°¨ì´ë¥¼ ë³´ì˜€ë‹¤. íŠ¹íˆ 60ëŒ€ ì´ìƒì€ í‰ê·  4.1ì ìœ¼ë¡œ ë‹¤ë¥¸ ì—°ë ¹ëŒ€ë³´ë‹¤ ë†’ì€ ê´€ì‹¬ì„ ë³´ì˜€ìœ¼ë©°, ê¸°ì €ì§ˆí™˜ìëŠ” â€˜ë§¤ìš° ê´€ì‹¬ ìˆë‹¤â€™ ë¹„ìœ¨ì´ ìƒëŒ€ì ìœ¼ë¡œ ë†’ì•˜ë‹¤. ì‹¤ì™¸ í™œë™ì´ ë§ì€ ê·¸ë£¹ ì—­ì‹œ ê´€ì‹¬ë„ í‰ê· ì´ 4.0ìœ¼ë¡œ ë†’ì€ í¸ì´ì—ˆë‹¤.
"""

def table_anaylsis_node_fn(state):
    print("*" * 10, "Start table anaylzing", "*" * 10)
    linearized_table = state["linearized_table"]
    numeric_anaylsis = state["numeric_anaylsis"]
    selected_question = state["selected_question"]

    response = llm.invoke(TABLE_PROMPT.format(selected_question = selected_question,
                                               linearized_table=linearized_table,
                                                 numeric_anaylsis=numeric_anaylsis))
    table_analysis = response.content.strip()

    # print("ğŸ’¬ Table Anaylsis ì‹œì‘")
    # print(f"ğŸ“ Linearlized Table:\n{linearized_table}")
    # print(f"ğŸ“„ ê²€ìƒ‰ëœ ë…¼ë¬¸ ìš”ì•½ (ë¯¸ë¦¬ë³´ê¸°):\n{retrieved_doc[:300]}...")

    return {**state, "table_analysis": table_analysis}

table_anaylsis_node = RunnableLambda(table_anaylsis_node_fn)