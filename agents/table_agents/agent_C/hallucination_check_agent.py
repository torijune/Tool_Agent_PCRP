import os
import openai

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableLambda

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.5)


HALLUCINATION_CHECK_PROMPT = """
ë‹¹ì‹ ì€ í†µê³„ í•´ì„ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ì˜ í…Œì´ë¸” ë°ì´í„°ì™€ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼, ê·¸ë¦¬ê³  í•´ë‹¹ í…Œì´ë¸”ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ëœ ìš”ì•½ ê²°ê³¼ê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤.

ğŸ“ ì„¤ë¬¸ ë¬¸í•­:
{selected_question}

ğŸ“Š ì„ í˜•í™”ëœ í…Œì´ë¸”:
{linearized_table}

ğŸ“ˆ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼:
{numeric_anaylsis}

ğŸ§¾ ìƒì„±ëœ ìš”ì•½:
{table_analysis}

ì´ ìš”ì•½ì´ ìœ„ì˜ í‘œì™€ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ë¥¼ **í¬ê²Œ ë²—ì–´ë‚˜ì§€ ì•Šê³  ì „ë°˜ì ìœ¼ë¡œ ì¼ê´€ì„± ìˆê²Œ** ë°˜ì˜í•˜ê³  ìˆëŠ”ì§€ í‰ê°€í•´ì£¼ì„¸ìš”.

âš ï¸ ì£¼ì˜:
- ì•½ê°„ì˜ í‘œí˜„ ì°¨ì´, ì–´ìˆœ ë³€í™”, ê²½ë¯¸í•œ í•´ì„ì  í‘œí˜„ì€ í—ˆìš©ë©ë‹ˆë‹¤.
- ë‹¤ë§Œ **ì¤‘ìš” ìˆ˜ì¹˜, ì£¼ìš” ê²½í–¥, ê·¸ë£¹ ê°„ ìˆœìœ„** ë“± í•µì‹¬ì ì¸ ì‚¬ì‹¤ ì™œê³¡ì´ ìˆìœ¼ë©´ reject í•˜ì„¸ìš”.

ğŸ¯ í‰ê°€ ë°©ì‹:
- ìš”ì•½ì´ ì „ì²´ì ìœ¼ë¡œ ì‹ ë¢°í•  ë§Œí•˜ê³  ì‚¬ì‹¤ ê¸°ë°˜ì´ë©´ "accept"ë¼ê³ ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
- ìš”ì•½ì—ì„œ **ëª…í™•í•œ ì‚¬ì‹¤ ì˜¤ë¥˜, ìˆ˜ì¹˜ ì™œê³¡, ì˜ëª»ëœ ê²°ë¡ **ì´ ìˆìœ¼ë©´ "reject: [ì´ìœ ]" í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
"""

def hallucination_check_node_fn(state):
    print("*" * 10, "Start table analysis hallucination check", "*" * 10)
    
    hallucination_reject_num = state.get("hallucination_reject_num", 0)

    if hallucination_reject_num == 0:
        prompt = HALLUCINATION_CHECK_PROMPT.format(
            selected_question=state["selected_question"],
            linearized_table=state["linearized_table"],
            numeric_anaylsis=state["numeric_anaylsis"],
            table_analysis=state["table_analysis"]
        )
    else:
        prompt = HALLUCINATION_CHECK_PROMPT.format(
            selected_question=state["selected_question"],
            linearized_table=state["linearized_table"],
            numeric_anaylsis=state["numeric_anaylsis"],
            table_analysis=state["revised_analysis"]
        )

    response = llm.invoke(prompt)
    result = response.content.strip()

    # "reject: ì´ìœ " í˜¹ì€ "accept"
    if result.lower().startswith("reject"):
        decision = "reject"
        feedback = result[len("reject"):].strip(": ").strip()
        hallucination_reject_num = hallucination_reject_num + 1
        print("Hallucination Check ê²°ê³¼: ", decision)
        print("\nLLM Feedback: ", feedback)
    else:
        decision = "accept"
        print("Hallucination Check ê²°ê³¼: ", decision)
        feedback = ""

    return {**state, 
            "hallucination_check": decision, 
            "feedback": feedback,
            "hallucination_reject_num": hallucination_reject_num
            }

hallucination_check_node = RunnableLambda(hallucination_check_node_fn)