import os
import openai

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableLambda

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)


REVISION_PROMPT = """
ë‹¤ìŒì€ í…Œì´ë¸” ë¶„ì„ ê²°ê³¼ì— ëŒ€í•´ ì¼ë¶€ ì˜ëª»ëœ í•´ì„ì´ í¬í•¨ëœ ìš”ì•½ì…ë‹ˆë‹¤. ì•„ë˜ì˜ í”¼ë“œë°±ì„ ì°¸ê³ í•˜ì—¬ ì˜ëª»ëœ ë‚´ìš©ì„ ì œê±°í•˜ê³ , ì›ë³¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±í•´ì£¼ì„¸ìš”.

ğŸ“ ì„¤ë¬¸ ë¬¸í•­: {selected_question}

ğŸ“Š ì„ í˜•í™”ëœ í…Œì´ë¸”:
{linearized_table}

ğŸ“ˆ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼:
{numeric_anaylsis}

ğŸ§¾ ê¸°ì¡´ ìš”ì•½ (ì˜ëª»ëœ ë¶€ë¶„ í¬í•¨):
{table_analysis}

â— í”¼ë“œë°± (ìˆ˜ì •ì´ í•„ìš”í•œ ì´ìœ  ë˜ëŠ” ì˜ëª»ëœ ë¶€ë¶„):
{feedback}

ğŸ“Œ ìˆ˜ì • ì¡°ê±´:
- í”¼ë“œë°±ì— ë”°ë¼ ì˜ëª»ëœ ì •ë³´ë¥¼ ì œê±°í•˜ê±°ë‚˜ ë³´ì™„í•´ì£¼ì„¸ìš”.
- ê°€ëŠ¥í•œ í•œ ìˆ˜ì¹˜ ê¸°ë°˜ì˜ ê°ê´€ì ì¸ í•´ì„ìœ¼ë¡œ ì„œìˆ í•´ì£¼ì„¸ìš”.
- 1~2ê°œì˜ ê°„ê²°í•œ ë‹¨ë½ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

def revise_table_analysis_fn(state):
    print("*" * 10, "Start table analysis revision", "*" * 10)
    prompt = REVISION_PROMPT.format(
        selected_question=state["selected_question"],
        linearized_table=state["linearized_table"],
        numeric_anaylsis=state["numeric_anaylsis"],
        table_analysis=state["table_analysis"],
        feedback=state.get("feedback", "í”¼ë“œë°± ì—†ìŒ")
    )

    response = llm.invoke(prompt)
    revised_analysis = response.content.strip()

    return {**state, "revised_analysis": revised_analysis }

revise_table_analysis = RunnableLambda(revise_table_analysis_fn)