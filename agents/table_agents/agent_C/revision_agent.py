import os
import openai

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableLambda

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)

REVISION_PROMPT = """
ë‹¹ì‹ ì€ í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸êµ¬ì§‘ë‹¨ ê°„ íŒ¨í„´ê³¼ ê²½í–¥ì„±ì„ ê°ê´€ì ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” í…Œì´ë¸” ë¶„ì„ ê²°ê³¼ì— ëŒ€í•´ ì¼ë¶€ ì˜ëª»ëœ í•´ì„ì´ í¬í•¨ëœ ìš”ì•½ì…ë‹ˆë‹¤. í”¼ë“œë°±ê³¼ ì‚¬ì „ì— ìƒì„±ëœ ê°€ì„¤ì„ ì°¸ê³ í•˜ì—¬ ì˜ëª»ëœ ë‚´ìš©ì„ ì œê±°í•˜ê³ , ì›ë³¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì¹˜ ê¸°ë°˜ì˜ ê°ê´€ì  ë¶„ì„ì„ ë‹¤ì‹œ ì‘ì„±í•  ê²ƒ.

ğŸ“ ì„¤ë¬¸ ì¡°ì‚¬ ì§ˆë¬¸:
{selected_question}

ğŸ“Š í‘œ ë°ì´í„° (ì„ í˜•í™”ëœ í˜•íƒœ):
{linearized_table}

ğŸ“ˆ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ (ëŒ€ë¶„ë¥˜ë³„ í•­ëª©ë³„ ìµœê³ /ìµœì € ê°’, í‘œì¤€í¸ì°¨, ë²”ìœ„ ë“±):
{numeric_anaylsis}

ğŸ’¡ ì‚¬ì „ì— ìƒì„±ëœ ê°€ì„¤ (ì°¸ê³ ìš©):
{generated_hypotheses}

ğŸ“ ê¸°ì¡´ ìš”ì•½ (ì˜ëª»ëœ ë¶€ë¶„ í¬í•¨):
{table_analysis}

â— í”¼ë“œë°± (ìˆ˜ì •ì´ í•„ìš”í•œ ì´ìœ  ë˜ëŠ” ì˜ëª»ëœ ë¶€ë¶„):
{feedback}

---

Let's think step by step

ğŸ¯ ìˆ˜ì • ë° ì¬ì‘ì„± ì§€ì¹¨:

1. ì£¼ìš” ëŒ€ë¶„ë¥˜ (ì˜ˆ: ì—°ë ¹ëŒ€, ê¸°ì €ì§ˆí™˜ ì—¬ë¶€, ëŒ€ê¸°ì˜¤ì—¼ ë°°ì¶œì‚¬ì—…ì¥ ìœ ë¬´, ì£¼ìš” ì²´ë¥˜ ê³µê°„ ë“±)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„í•  ê²ƒ
2. ì„¸ë¶€ ì†Œë¶„ë¥˜ (ì˜ˆ: ì„±ë³„, 20ëŒ€/30ëŒ€ ë“± ì„¸ë¶€ ì—°ë ¹ êµ¬ê°„)ëŠ” ëª…í™•í•œ ì°¨ì´ê°€ ì—†ì„ ê²½ìš° ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ ê²ƒ
3. ì˜ë¯¸ ìˆëŠ” ì°¨ì´ê°€ ë‚˜íƒ€ë‚˜ëŠ” ì£¼ìš” ê·¸ë£¹ë§Œ ì„ íƒì ìœ¼ë¡œ ì–¸ê¸‰í•  ê²ƒ
4. ëª¨ë“  ì„¸ë¶€ ê·¸ë£¹ì„ ë‚˜ì—´í•˜ì§€ ë§ê³ , íŠ¹ì§•ì ì¸ ê·¸ë£¹ê³¼ ì£¼ìš” ì°¨ì´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ìš”ì•½í•  ê²ƒ
5. ì™¸ë¶€ ë°°ê²½ì§€ì‹, ì£¼ê´€ì  í•´ì„ ì—†ì´ ì˜¤ì§ ìˆ˜ì¹˜ ê¸°ë°˜ì˜ ì‚¬ì‹¤ë§Œ ì‘ì„±í•  ê²ƒ
6. ìˆ«ì ê¸°ë°˜ì˜ ê²½í–¥ì„ ì¤‘ì‹¬ìœ¼ë¡œ "ìƒëŒ€ì ìœ¼ë¡œ ë” ë†’ì€ ê²½í–¥ ë³´ì˜€ìŒ", "ë‚®ì€ ê°’ì„ ë‚˜íƒ€ëƒˆìŒ" ë“± **ìŒìŠ´ì²´**ë¡œ ì‘ì„±í•  ê²ƒ
7. ë¬¸ì¥ì€ í‰ì„œë¬¸ì´ ì•„ë‹Œ, **ë³´ê³ ì„œ ìŒìŠ´ì²´ ìŠ¤íƒ€ì¼**ë¡œ ì‘ì„±í•  ê²ƒ (ì˜ˆ: ~í–ˆìŒ, ~ë¡œ ë‚˜íƒ€ë‚¬ìŒ)
8. ì •í™•í•œ ìˆ˜ì¹˜ê°’ì€ ì“°ì§€ ë§ê³ , ìˆ˜ì¹˜ ì°¨ì´ì— ê¸°ë°˜í•œ ê²½í–¥ë§Œ ì„œìˆ í•  ê²ƒ
9. ì§€ë‚˜ì¹˜ê²Œ ë‹¨ì ˆì  (~í–ˆìŒ. ~í–ˆìŒ. ë°˜ë³µ) í‘œí˜„ì„ ì§€ì–‘í•˜ê³ , ê´€ë ¨ëœ ê·¸ë£¹ë“¤ì€ **ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ì–´ë¥¼ ì‚¬ìš©í•´ í•œ ë¬¸ì¥ìœ¼ë¡œ ë¬¶ì„ ê²ƒ**
10. ë™ì¼ ì˜ë¯¸ì˜ ê·¸ë£¹ì´ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•  ê²ƒ

---

ğŸ“ ì¶œë ¥ í˜•ì‹:

- ì œëª©, ë¶ˆë¦¿, ë¦¬ìŠ¤íŠ¸ ì—†ì´ ì„œìˆ í˜•ìœ¼ë¡œ ì‘ì„±í•  ê²ƒ
- ì§§ê³  ëª…í™•í•˜ê²Œ ë¶„ì„ ê²°ê³¼ë§Œ ìš”ì•½í•  ê²ƒ
- ì•„ë˜ ì˜ˆì‹œì²˜ëŸ¼ ì‘ì„±í•  ê²ƒ

ì˜ˆì‹œ:
ëŒ€ê¸°í™˜ê²½ ë¬¸ì œ ê´€ì‹¬ ì •ë„, ì—°ë ¹ëŒ€ ë†’ì„ìˆ˜ë¡ ë” ë†’ì€ ê²½í–¥ ë³´ì˜€ìŒ. ê¸°ì €ì§ˆí™˜ ìˆëŠ” ê·¸ë£¹, ëŒ€ê¸°ì˜¤ì—¼ ë°°ì¶œì‚¬ì—…ì¥ ì£¼ë³€ ê±°ì£¼ ê·¸ë£¹, ì‹¤ì™¸ ì²´ë¥˜ì‹œê°„ ë§ì€ ê·¸ë£¹ë„ ìƒëŒ€ì ìœ¼ë¡œ ë†’ì€ ê´€ì‹¬ ë³´ì˜€ìŒ.
"""

def revise_table_analysis_fn(state):
    print("\n********** Start table analysis revision **********")

    if state["hallucination_reject_num"] == 0:
        prompt = REVISION_PROMPT.format(
            selected_question=state["selected_question"],
            linearized_table=state["linearized_table"],
            numeric_anaylsis=state["numeric_anaylsis"],
            table_analysis=state["table_analysis"],
            feedback=state["feedback"],
            generated_hypotheses=state.get("generated_hypotheses", "í•´ë‹¹ ì—†ìŒ")
        )
    else:
        prompt = REVISION_PROMPT.format(
            selected_question=state["selected_question"],
            linearized_table=state["linearized_table"],
            numeric_anaylsis=state["numeric_anaylsis"],
            table_analysis=state["revised_analysis"],
            feedback=state["feedback"],
            generated_hypotheses=state.get("generated_hypotheses", "í•´ë‹¹ ì—†ìŒ")
        )

    response = llm.invoke(prompt)
    revised_analysis = response.content.strip()

    print("\nâœ… ìˆ˜ì •ëœ ë³´ê³ ì„œ:")
    print(revised_analysis)

    return {
        **state,
        "revised_analysis": revised_analysis
    }

revise_table_analysis_node = RunnableLambda(revise_table_analysis_fn)