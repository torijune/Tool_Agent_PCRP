from langchain_core.runnables import RunnableLambda
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain.schema.document import Document
from typing import List
from dotenv import load_dotenv
from tqdm import tqdm
import json, os

load_dotenv()
embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")

DATA_PATH = "agents/abstract_agents/data/EMNLP_ACL_NAACL_Abstracts.json"
FAISS_PATH = "agents/abstract_agents/data/faiss_index"

# ğŸ”¹ ë¬¸ì„œ ë¡œë”© í•¨ìˆ˜
def load_documents(path: str) -> List[Document]:
    print(f"ğŸ“„ ë¬¸ì„œ ë¡œë”© ì¤‘: {path}")
    with open(path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    filtered = [
        Document(
            page_content=item["abstract"],
            metadata={"title": item.get("title", ""), "url": item.get("url", "")}
        )
        for item in data if item.get("abstract") and item.get("title")
    ]
    print(f"âœ… ì´ ìœ íš¨ ë¬¸ì„œ ìˆ˜: {len(filtered)}")
    return filtered

if os.path.exists(FAISS_PATH):
    print("ğŸ“ ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.")
    vectorstore = FAISS.load_local(FAISS_PATH, 
                                   embeddings=embedding_model, 
                                   index_name="papers", 
                                   allow_dangerous_deserialization=True)
else:
    print("ğŸ†• ìƒˆë¡œ ì„ë² ë”©í•˜ê³  FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    documents = load_documents(DATA_PATH)

    class TrackedEmbedding(OpenAIEmbeddings):
        def embed_documents(self, texts: List[str]) -> List[List[float]]:
            print(f"ğŸ” ì´ ë¬¸ì„œ ìˆ˜: {len(texts)} â†’ ì„ë² ë”© ì‹œì‘")
            for _ in tqdm(range(len(texts)), desc="ğŸ“¦ Embedding ì§„í–‰ ì¤‘", unit="docs"):
                pass
            return super().embed_documents(texts)

    tracked_model = TrackedEmbedding(model="text-embedding-3-small")
    vectorstore = FAISS.from_documents(documents, tracked_model)
    vectorstore.save_local(FAISS_PATH, index_name="papers")
    print("âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ")

# ğŸ”¹ Retriever êµ¬ì„±
print("ğŸ”— Retriever êµ¬ì„± ì™„ë£Œ")
retriever = vectorstore.as_retriever(search_type="similarity", k=3)

# ğŸ”¹ LangGraphìš© nodeë¡œ ì‚¬ìš©ë  í•¨ìˆ˜ ì •ì˜
def retriever_node(state: dict) -> dict:
    query = state["query"]
    print(f"ğŸ” ì§ˆì˜ ì²˜ë¦¬ ì¤‘: \"{query}\"")
    docs = retriever.get_relevant_documents(query)
    print(f"ğŸ“š ê´€ë ¨ ë¬¸ì„œ ìˆ˜: {len(docs)}")

    combined = "\n\n".join([
        f"ì œëª©: {doc.metadata['title']}\nìš”ì•½: {doc.page_content}"
        for doc in docs
    ])
    return {**state, "retrieved_doc": combined}

retriever_node = RunnableLambda(retriever_node)