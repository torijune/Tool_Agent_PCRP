import os
from dotenv import load_dotenv
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI

load_dotenv()
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)

HALLUCINATION_PROMPT = """ë‹¹ì‹ ì€ ì •í™•í•œ ì •ë³´ë¥¼ íŒë‹¨í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒì€ ì‚¬ìš©ì ì§ˆë¬¸(query), ê·¸ì— ëŒ€í•œ ê²€ìƒ‰ëœ ë…¼ë¬¸ ì •ë³´(retrieved_doc), ê·¸ë¦¬ê³  ê·¸ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ëœ AIì˜ ì‘ë‹µ(answer)ì…ë‹ˆë‹¤.

ì§ˆë¬¸:
{query}

ê²€ìƒ‰ëœ ë…¼ë¬¸ ìš”ì•½:
{retrieved_doc}

AI ì‘ë‹µ:
{answer}

ìœ„ì˜ AI ì‘ë‹µì´ ê²€ìƒ‰ëœ ë…¼ë¬¸ ìš”ì•½(retrieved_doc)ì— ëª…í™•í•˜ê²Œ ê·¼ê±°í•˜ê³  ìˆìœ¼ë©´ 'accept'ë¼ê³  ì¶œë ¥í•˜ê³ , ê·¼ê±° ì—†ì´ ìƒì„±ëœ ë‚´ìš©(hallucination)ì´ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ 'reject'ë¼ê³  ì¶œë ¥í•˜ì„¸ìš”.

ë‹¨ë‹µìœ¼ë¡œ only 'accept' ë˜ëŠ” 'reject'ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

def hallucination_check_node(state: dict) -> dict:
    query = state["query"]
    retrieved_doc = state["retrieved_doc"]
    answer = state["generated_answer"]

    print("ğŸ§  Hallucination Check ì‹œì‘")
    print(f"â“ ì‚¬ìš©ì ì§ˆë¬¸:\n{query}")
    print(f"ğŸ“„ ê²€ìƒ‰ëœ ë…¼ë¬¸ ìš”ì•½ (ë¯¸ë¦¬ë³´ê¸°):\n{retrieved_doc[:300]}...")
    print(f"ğŸ’¬ AI ì‘ë‹µ:\n{answer}")

    decision = llm.invoke(
        HALLUCINATION_PROMPT.format(query=query, retrieved_doc=retrieved_doc, answer=answer)
    ).content.strip().lower()

    print(f"âœ… íŒë‹¨ ê²°ê³¼: {decision}")
    print("-" * 60)

    return {**state, "hallucination_decision": decision}

hallucination_check_node = RunnableLambda(hallucination_check_node)