def rule_based_test_type_decision(columns, question_text=""):
    """
    ì»¬ëŸ¼ëª…ê³¼ ì§ˆë¬¸ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„ì˜ ë¶„ì„/ft_test/chi_squareë¥¼ rule ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨
    """
    import re

    # 1ï¸âƒ£ ì„ì˜ ë¶„ì„ íŒë‹¨: ë³µìˆ˜ ì‘ë‹µ ë˜ëŠ” ìˆœìœ„ ì‘ë‹µ íŒ¨í„´ ì¡´ì¬ ì—¬ë¶€
    multi_response_keywords = [
        "1+2", "1+2+3", "ë³µìˆ˜", "ë‹¤ì¤‘", "multiple", "rank", "ranking", "ìš°ì„ ìˆœìœ„"
    ]
    text_to_check = (" ".join(columns) + " " + question_text).lower()
    if any(keyword.lower() in text_to_check for keyword in multi_response_keywords):
        return "manual"

    # 2ï¸âƒ£ ft_test íŒë‹¨ ê¸°ì¤€: ì „í˜•ì ì¸ ë²”ì£¼í˜• í‘œí˜„ì´ ìˆëŠ” ê²½ìš°
    categorical_patterns = [
        # ê´€ì‹¬ë„ ê´€ë ¨
        r"ì „í˜€\s*ê´€ì‹¬", r"ê´€ì‹¬\s*ì—†(ë‹¤|ëŠ”)", r"ê´€ì‹¬\s*ìˆ(ë‹¤|ëŠ”)", r"ë§¤ìš°\s*ê´€ì‹¬", r"ê´€ì‹¬",

        # ë§Œì¡±ë„ ê´€ë ¨
        r"ë§¤ìš°\s*ë§Œì¡±", r"ë§Œì¡±", r"ë¶ˆë§Œì¡±", r"ë§¤ìš°\s*ë¶ˆë§Œì¡±", r"ë³´í†µ",

        # ì°¬ë°˜ ê´€ë ¨
        r"ì°¬ì„±", r"ë°˜ëŒ€", r"ë§¤ìš°\s*ì°¬ì„±", r"ë§¤ìš°\s*ë°˜ëŒ€", r"ëŒ€ì²´ë¡œ\s*ì°¬ì„±", r"ëŒ€ì²´ë¡œ\s*ë°˜ëŒ€",

        # ì¤‘ìš”ë„ ê´€ë ¨
        r"ë§¤ìš°\s*ì¤‘ìš”", r"ì¤‘ìš”", r"ê·¸ë‹¤ì§€\s*ì¤‘ìš”í•˜ì§€\s*ì•Š", r"ì „í˜€\s*ì¤‘ìš”í•˜ì§€\s*ì•Š",

        # ì‹¬ê°ì„± ì¸ì‹
        r"ë§¤ìš°\s*ì‹¬ê°", r"ì‹¬ê°", r"ì‹¬ê°í•˜ì§€\s*ì•Š", r"ì „í˜€\s*ì‹¬ê°í•˜ì§€\s*ì•Š",

        # ë¹ˆë„ ê´€ë ¨
        r"ìì£¼", r"ê°€ë”", r"ê±°ì˜\s*ì—†", r"ì „í˜€\s*ì—†",

        # ì•ˆì „ì„± ê´€ë ¨
        r"ì•ˆì „", r"ë§¤ìš°\s*ì•ˆì „", r"ìœ„í—˜", r"ë§¤ìš°\s*ìœ„í—˜",

        # ì¸ì§€/ê²½í—˜ ì—¬ë¶€
        r"ë“¤ì–´ë³¸\s*ì ", r"ì‚¬ìš©í•œ\s*ì ", r"ê²½í—˜í–ˆ", r"ì¸ì§€",

        # íƒœë„/ì˜í–¥ ê´€ë ¨
        r"ì˜í–¥", r"ìƒê°", r"ì˜ˆì •", r"ê³„íš", r"í• \s*ê²ƒ",

        # ì •ë„ í‘œí˜„
        r"ë§¤ìš°", r"ì•½ê°„", r"ë³´í†µ", r"ê·¸ë‹¤ì§€", r"ì „í˜€"
    ]
    if any(any(re.search(pattern, col) for pattern in categorical_patterns) for col in columns):
        return "ft_test"

    # 3ï¸âƒ£ ë‚˜ë¨¸ì§€ëŠ” chi_square
    return "chi_square"
import os
import openai
import streamlit as st

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableLambda

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° API í‚¤ ì„¤ì •
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# âœ… LLM ì„¤ì •
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.0)


TEST_TYPE_PROMPT = """
ë‹¹ì‹ ì€ í†µê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” ì„¤ë¬¸ ì‘ë‹µ ê²°ê³¼ í…Œì´ë¸”ì˜ ì—´ ì´ë¦„ ëª©ë¡ì…ë‹ˆë‹¤. ì´ ì—´ë“¤ì€ ì‘ë‹µìë“¤ì´ ì„ íƒí•˜ê±°ë‚˜ í‰ê°€í•œ ì„¤ë¬¸ ë¬¸í•­ì˜ ê²°ê³¼ë¡œ êµ¬ì„±ëœ í†µê³„í‘œì…ë‹ˆë‹¤.

ë‹¹ì‹ ì˜ ì„ë¬´ëŠ”, ì´ í…Œì´ë¸”ì´ **ì–´ë–¤ í†µê³„ ê²€ì •(F/T-test ë˜ëŠ” Chi-square)** ì— ì í•©í•œì§€ë¥¼ íŒë‹¨í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ğŸ“‹ ì—´ ì´ë¦„ ëª©ë¡:
{column_names}

---
Let's think step by step

íŒë‹¨ ê¸°ì¤€:

- `ft_test` (ì—°ì†í˜• ìˆ˜ì¹˜ ì‘ë‹µ):
    - ë¬¸í•­ì´ 1~5ì  ì²™ë„, í‰ê· , ë¹„ìœ¨, ì ìˆ˜ ë“± ìˆ«ì ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½ë˜ì–´ ìˆë‹¤ë©´ F-test ë˜ëŠ” T-testê°€ ì ì ˆí•©ë‹ˆë‹¤.
    - ì˜ˆì‹œ ì—´ ì´ë¦„: "í‰ê· ", "ë§Œì¡±ë„ ì ìˆ˜", "~% ë¹„ìœ¨", "5ì  ì²™ë„", "í‰ê·  ì ìˆ˜", "ê´€ì‹¬ë„ í‰ê· "
    - "ì „í˜€ ê´€ì‹¬ì´ ì—†ë‹¤", "ë§¤ìš° ê´€ì‹¬ ìˆë‹¤" ë“±ì€ ì‹¤ì œë¡œëŠ” ì„ íƒì§€ì´ì§€ë§Œ, ë¹ˆë„ë‚˜ ë¹„ìœ¨ë¡œ ìˆ˜ì¹˜í™”ë˜ì—ˆì„ ê²½ìš° â†’ ì—°ì†í˜•ìœ¼ë¡œ íŒë‹¨

- `chi_square` (ë²”ì£¼í˜• ì„ íƒ ì‘ë‹µ):
    - ë¬¸í•­ì´ ì‘ë‹µìë“¤ì´ íŠ¹ì • í•­ëª©ì„ **ì„ íƒ**í•˜ê±°ë‚˜ **ë‹¤ì¤‘ì„ íƒ**í•œ ê²°ê³¼ì¼ ê²½ìš°, ë²”ì£¼í˜• ì‘ë‹µìœ¼ë¡œ ë³´ê³  ì¹´ì´ì œê³± ê²€ì •ì´ ì í•©í•©ë‹ˆë‹¤.
    - ì˜ˆì‹œ ì—´ ì´ë¦„: "ì£¼ìš” ì´ìš©ì‹œì„¤", "ì„ íƒ ì´ìœ ", "ê°€ì¥ ë§ì´ ì„ íƒí•œ ì¥ì†Œ", "ë‹¤ì¤‘ ì‘ë‹µ"

â— ì˜¤íŒ ì£¼ì˜:
- ì‘ë‹µ ì„ íƒì§€ ì´ë¦„(ì˜ˆ: "ì „í˜€ ê´€ì‹¬ ì—†ë‹¤", "ë§¤ìš° ê´€ì‹¬ ìˆë‹¤")ê°€ ì—´ ì´ë¦„ì— í¬í•¨ë˜ë”ë¼ë„, **ë¹„ìœ¨, í‰ê·  ë“±ì˜ ìˆ˜ì¹˜í˜• ìš”ì•½**ì´ë©´ `ft_test`ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.
- í…Œì´ë¸”ì´ ì „ì²´ì ìœ¼ë¡œ í‰ê· ê°’ ë˜ëŠ” %ë¹„ìœ¨ ì¤‘ì‹¬ì´ë©´ `ft_test` ì„ íƒì´ ë” ì ì ˆí•©ë‹ˆë‹¤.

---

ğŸ“Œ ë‹µë³€ í˜•ì‹: ì•„ë˜ì˜ í˜•ì‹ì²˜ëŸ¼ ì„ íƒì˜ ì´ìœ ì— ëŒ€í•´ì„œ ë‹µë³€í•˜ì§€ ë§ê³  "ì í•©í•œ í†µê³„ ê²€ì •ì˜ ë°©ë²•ë§Œ" ì¶œë ¥í•˜ì„¸ìš”.

- ë°˜ë“œì‹œ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µí•´ì£¼ì„¸ìš” (ì†Œë¬¸ì):
    - ft_test
    - chi_square

ì í•©í•œ í†µê³„ ë°©ë²•: (ft_test ë˜ëŠ” chi_square)
"""

def normalize_test_type(llm_output: str) -> str:
    if "chi" in llm_output.lower():
        return "chi_square"
    elif "ft" in llm_output.lower():
        return "ft_test"
    else:
        return "unknown"

def streamlit_test_type_decision_fn(state):
    lang = state.get("lang", "í•œêµ­ì–´")
    selected_table = state["selected_table"]

    IGNORE_COLUMNS = {"ëŒ€ë¶„ë¥˜", "ì†Œë¶„ë¥˜", "ì‚¬ë¡€ìˆ˜", "row_name"}
    filtered_columns = [col for col in selected_table.columns if col not in IGNORE_COLUMNS]

    question_text = state.get("selected_question", "")
    manual_check = rule_based_test_type_decision(filtered_columns, question_text)
    if manual_check == "manual":
        return {**state, "test_type": "manual"}


    question_key = state.get("selected_key", "")
    user_analysis_plan = state.get("user_analysis_plan", {})
    user_decision = user_analysis_plan.get(question_key, {})

    if isinstance(user_decision, dict) and user_decision.get("use_stat") is False:
        return {**state, "test_type": None}

    if isinstance(user_decision, dict) and user_decision.get("test_type") in ["ft_test", "chi_square"]:
        return {**state, "test_type": user_decision["test_type"]}

    column_names_str = ", ".join(filtered_columns)

    prompt = TEST_TYPE_PROMPT.format(
        column_names=column_names_str
    )

    if state.get("analysis_type", True):
        st.info("ğŸ¤– LLMì—ê²Œ ì ì ˆí•œ í†µê³„ ê²€ì • ë°©ì‹ì„ ë¬¸ì˜í•©ë‹ˆë‹¤..." if lang == "í•œêµ­ì–´" else "ğŸ¤– Asking the LLM to determine the appropriate statistical test...")

    if state.get("analysis_type", True):
        with st.spinner("LLM íŒë‹¨ ì¤‘..." if lang == "í•œêµ­ì–´" else "Determining test type..."):
            response = llm.invoke(prompt)
    else:
        response = llm.invoke(prompt)

    test_type = response.content.strip()
    test_type = normalize_test_type(test_type)

    if state.get("analysis_type", True):
        st.success(f"ğŸ“Œ LLM ê²°ì •: `{test_type}` ê²€ì • ë°©ì‹ ì„ íƒë¨" if lang == "í•œêµ­ì–´" else f"ğŸ“Œ LLM decision: `{test_type}` test selected")

    return {
        **state,
        "test_type": test_type
    }


streamlit_test_type_decision_node = RunnableLambda(streamlit_test_type_decision_fn)