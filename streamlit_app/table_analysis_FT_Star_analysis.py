from langchain_core.runnables import RunnableLambda
import pandas as pd
import scipy.stats as stats
import io
import re
import streamlit as st

# âœ… ìœ ì˜ì„± ë³„ ë¶€ì—¬ í•¨ìˆ˜
def assign_significance_stars(p_value):
    if p_value < 0.001:
        return "***"
    elif p_value < 0.01:
        return "**"
    elif p_value < 0.05:
        return "*"
    else:
        return ""

# âœ… DEMO ë§¤í•‘ ì¶”ì¶œ í•¨ìˆ˜
def extract_demo_mapping_from_dataframe(df, column="Unnamed: 0"):
    col = df[column].dropna().astype(str).reset_index(drop=True)
    cut_idx = None
    for i, val in enumerate(col):
        if val.strip() == 'DEMO1':
            cut_idx = i
            break
    sliced = col[:cut_idx] if cut_idx is not None else col

    demo_dict = {}
    for entry in sliced:
        entry = str(entry).strip()
        match = re.match(r"(DEMO\d+)[\s'\"]+(.+?)['\"\s\.]*$", entry)
        if match:
            key = match.group(1)
            label = match.group(2).strip()
            demo_dict[key] = label

    return demo_dict

# âœ… ìì—°ì–´ ìš”ì•½ ìƒì„± í•¨ìˆ˜
def summarize_ft_test(result_df: pd.DataFrame, lang: str = "í•œêµ­ì–´") -> str:
    # ìœ ì˜ì„± ìˆëŠ” í•­ëª©(ë³„ì´ í•˜ë‚˜ ì´ìƒ ë¶™ì€ í•­ëª©) í•„í„°ë§
    significant = result_df[result_df["ìœ ì˜ì„±"] != ""]
    non_significant = result_df[result_df["ìœ ì˜ì„±"] == ""]

    summary = []

    if not significant.empty:
        sig_items = significant["ëŒ€ë¶„ë¥˜"].tolist()
        if len(sig_items) == len(result_df):
            summary.append("ëª¨ë“  í•­ëª©ì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ê´€ì°°ë˜ì—ˆìŒ. ëŒ€ë¶„ë¥˜ ì „ë°˜ì— ê±¸ì³ ì˜ë¯¸ ìˆëŠ” ì°¨ì´ê°€ ì¡´ì¬í•¨." if lang == "í•œêµ­ì–´" else "All categories showed statistically significant differences. Broad variation was observed across major groups.")
        else:
            summary.append(f"{', '.join(sig_items)}ëŠ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì°¨ì´ë¥¼ ë³´ì˜€ìŒ." if lang == "í•œêµ­ì–´" else f"{', '.join(sig_items)} showed statistically significant differences.")
    else:
        # ìœ ì˜í•œ í•­ëª©ì´ ì „í˜€ ì—†ì„ ê²½ìš° â†’ p-value ê¸°ì¤€ ìƒìœ„ 3ê°œ ì–¸ê¸‰
        if not result_df.empty:
            top3 = result_df.nsmallest(3, "p-value")[["ëŒ€ë¶„ë¥˜", "p-value"]]
            top3_text = ", ".join(f"{row['ëŒ€ë¶„ë¥˜']} (p={row['p-value']})" for _, row in top3.iterrows())
            summary.append(f"í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ í•­ëª©ì€ ì—†ì—ˆì§€ë§Œ, ìƒëŒ€ì ìœ¼ë¡œ p-valueê°€ ë‚®ì€ í•­ëª©ì€ {top3_text} ìˆœì´ì—ˆìŒ." if lang == "í•œêµ­ì–´" else f"No items reached statistical significance, but the ones with the lowest p-values were: {top3_text}.")

    return "  ".join(summary)

def run_statistical_tests(test_type, df, question_key, demo_dict):
    # âœ… F/T-test ì‹¤í–‰ í•¨ìˆ˜
    def run_ft_test_df(df: pd.DataFrame, question_key: str, demo_dict: dict) -> pd.DataFrame:
        question_key = question_key.strip()
        rows = []

        for demo_col, label in demo_dict.items():
            if demo_col not in df.columns:
                continue

            try:
                groups = df.groupby(demo_col)[question_key].apply(list)
                group_values = [pd.Series(values).dropna().tolist() for values in groups]

                if len(group_values) < 2:
                    continue

                levene_stat, levene_p = stats.levene(*group_values)

                if len(group_values) == 2:
                    test_stat, test_p = stats.ttest_ind(
                        group_values[0], group_values[1],
                        equal_var=(levene_p > 0.05)
                    )
                else:
                    test_stat, test_p = stats.f_oneway(*group_values)

                row = {
                    "ëŒ€ë¶„ë¥˜": label,
                    "í†µê³„ëŸ‰": round(abs(test_stat), 3),
                    "p-value": round(test_p, 4),
                    "ìœ ì˜ì„±": assign_significance_stars(test_p)
                }
                rows.append(row)

            except Exception:
                continue

        result_df = pd.DataFrame(rows)
        return result_df
    
    def run_chi_square_test_df(df: pd.DataFrame, question_key: str, demo_dict: dict) -> pd.DataFrame:
        question_key = question_key.strip()
        if question_key not in df.columns:
            st.error(f"âŒ ì§ˆë¬¸ í•­ëª© '{question_key}' ì´(ê°€) ë°ì´í„°ì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return pd.DataFrame([])

        rows = []

        for demo_col, label in demo_dict.items():
            if demo_col not in df.columns:
                st.warning(f"âŒ DEMO ì»¬ëŸ¼ ëˆ„ë½: {demo_col}")
                continue

            try:
                contingency_table = pd.crosstab(df[demo_col], df[question_key])

                if contingency_table.shape[0] < 2 or contingency_table.shape[1] < 2:
                    st.info(f"âš ï¸ ìŠ¤í‚µë¨: {label} - êµì°¨í‘œ í¬ê¸° ë¶€ì¡±")
                    continue

                chi2, p, dof, expected = stats.chi2_contingency(contingency_table)

                row = {
                    "ëŒ€ë¶„ë¥˜": label,
                    "í†µê³„ëŸ‰": round(chi2, 3),
                    "p-value": round(p, 4),
                    "ìœ ì˜ì„±": assign_significance_stars(p)
                }
                rows.append(row)

            except Exception as e:
                st.error(f"âŒ Chi-square ì‹¤íŒ¨: {label} / {str(e)}")
                continue

        return pd.DataFrame(rows)
    
    if test_type == "ft_test":
        return run_ft_test_df(df, question_key, demo_dict)
    elif test_type =="chi_square":
        return run_chi_square_test_df(df, question_key, demo_dict)
    else:
        raise ValueError(f"âŒ ì˜ëª»ëœ test_type: {test_type}")




# âœ… LangGraph ë…¸ë“œ í•¨ìˆ˜
def ft_star_analysis_node_fn(state: dict) -> dict:
    try:

        raw_data_file = state["raw_data_file"]
        question_key = state["selected_key"].strip()
        test_type = state["test_type"]
        lang = state.get("lang", "í•œêµ­ì–´")

        st.info(f"âœ… [FT-Test Agent] {test_type} ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤..." if lang == "í•œêµ­ì–´" else f"âœ… [FT-Test Agent] Starting {test_type} analysis...")

        with st.spinner("ğŸ” F/T ë¶„ì„ ì§„í–‰ ì¤‘..." if lang == "í•œêµ­ì–´" else "ğŸ” Running F/T analysis..."):

            raw_data = pd.read_excel(raw_data_file, sheet_name="DATA")
            demo_df = pd.read_excel(raw_data_file, sheet_name="DEMO")

            # âœ… ì»¬ëŸ¼ëª… ì •ê·œí™”: '-' â†’ '_', ê·¸ë¦¬ê³  ì–‘ìª½ ê³µë°± ì œê±°
            raw_data.columns = [col.replace("-", "_").strip() for col in raw_data.columns]

            demo_mapping = extract_demo_mapping_from_dataframe(demo_df)

            result_df = run_statistical_tests(test_type = test_type,
                                            df = raw_data,
                                            question_key=question_key,
                                            demo_dict=demo_mapping)

            # âœ… Streamlit ì¶œë ¥
            st.markdown("### âœ… F/T ê²€ì • ê²°ê³¼" if lang == "í•œêµ­ì–´" else "### âœ… F/T Test Results")
            st.dataframe(result_df)

            # âœ… ìì—°ì–´ ìš”ì•½ ì¶œë ¥
            summary_text = summarize_ft_test(result_df, lang=lang)
            st.markdown("### ğŸ“„ ìì—°ì–´ ìš”ì•½ ê²°ê³¼" if lang == "í•œêµ­ì–´" else "### ğŸ“„ Natural Language Summary")
            st.write(summary_text)

            print("âœ… F/T ë¶„ì„ ì™„ë£Œ")

        return {
            **state,
            "raw_data": raw_data,
            "ft_test_result": result_df,
            "ft_test_summary": summary_text,
        }

    except Exception as e:
        print("âŒ F/T ë¶„ì„ ì¤‘ ì˜¤ë¥˜:", e)
        st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}" if lang == "í•œêµ­ì–´" else f"âŒ Error during analysis: {e}")
        return {**state, "ft_test_result": {}, "ft_error": str(e)}

# âœ… LangGraph ë…¸ë“œ ë“±ë¡
streamlit_ft_star_analysis_node = RunnableLambda(ft_star_analysis_node_fn)