import os
import openai
import streamlit as st

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableLambda

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° API í‚¤ ì„¤ì •
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# âœ… LLM ì„¤ì •
llm = ChatOpenAI(model="gpt-4o-mini", temperature=1.0, top_p = 0.9, openai_api_key=api_key)

HALLUCINATION_CHECK_PROMPT = """
ë‹¹ì‹ ì€ í†µê³„ í•´ì„ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ì˜ í…Œì´ë¸” ë°ì´í„°ì™€ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼(F/T-test ê¸°ë°˜), ê·¸ë¦¬ê³  í•´ë‹¹ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ëœ ìš”ì•½ ë³´ê³ ì„œê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤.

ğŸ“ ì„¤ë¬¸ ë¬¸í•­:
{selected_question}

ğŸ“Š ì„ í˜•í™”ëœ í…Œì´ë¸”:
{linearized_table}

ğŸ“ˆ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ (F/T-test ê²°ê³¼ ìš”ì•½):
{ft_test_summary}

ğŸ§¾ ìƒì„±ëœ ìš”ì•½:
{table_analysis}

---

ì´ ìš”ì•½ì´ ìœ„ì˜ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ë¥¼ **ì •í™•í•˜ê³  ì¼ê´€ì„± ìˆê²Œ** ë°˜ì˜í•˜ê³  ìˆëŠ”ì§€ í‰ê°€í•´ì£¼ì„¸ìš”.

âš ï¸ ì£¼ì˜ ì‚¬í•­ (ìœ„ë°˜ ì‹œ ìš°ì„  í”¼ë“œë°± ì œê³µ, ì‹¬ê°í•œ ì™œê³¡ì— í•œí•´ reject):
1. F/T-testì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ í™•ì¸ëœ ëŒ€ë¶„ë¥˜ê°€ ìš”ì•½ì— ì–¸ê¸‰ë˜ì§€ ì•Šì€ ê²½ìš°
2. ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ í™•ì¸ëœ ëŒ€ë¶„ë¥˜ì—ì„œì˜ ì£¼ìš” ê²½í–¥ì´ë‚˜ ìˆ˜ì¹˜ ê²°ê³¼ê°€ ì™œê³¡ë˜ì–´ í•´ì„ëœ ê²½ìš° (e.g. ë” ë†’ì§€ ì•Šì€ë° ë” ë†’ë‹¤ê³  ì˜ëª» ëœ ì£¼ì¥ì„ í•˜ëŠ” ê²½ìš°)

ğŸ¯ í‰ê°€ ë°©ì‹:
- ìš”ì•½ì´ ì „ì²´ì ìœ¼ë¡œ ì‹ ë¢°í•  ë§Œí•˜ê³  í†µê³„ ê²°ê³¼ë¥¼ ì˜ ë°˜ì˜í•˜ë©´ "accept"
- ìœ„ í•­ëª© ìœ„ë°˜ ì‹œ "reject: [ì´ìœ ]" í˜•ì‹ìœ¼ë¡œ ì¶œë ¥

â€» F/T-test ê²°ê³¼ëŠ” ì¤‘ìš”í•œ ê¸°ì¤€ì´ì§€ë§Œ, ì‚¬ì†Œí•œ ëˆ„ë½ì€ reject ëŒ€ì‹  í”¼ë“œë°±ìœ¼ë¡œ ì²˜ë¦¬í•´ë„ ë©ë‹ˆë‹¤. ëª…ë°±í•œ ì™œê³¡ì´ë‚˜ ì¤‘ëŒ€í•œ ëˆ„ë½ ì‹œì—ë§Œ reject í•˜ì„¸ìš”.
"""

# âœ… LangGraph-compatible hallucination ì²´í¬ ë…¸ë“œ
def streamlit_hallucination_check_node_fn(state):
    st.info("âœ… [Hallucination Check Agent] Start hallucination evaluation")

    hallucination_reject_num = state.get("hallucination_reject_num", 0)

    # ğŸ” ìˆ˜ì • ì—¬ë¶€ì— ë”°ë¼ ë¶„ì„ ê²°ê³¼ ì„ íƒ
    if "revised_analysis_history" in state and state["revised_analysis_history"]:
        table_analysis = state["revised_analysis_history"][-1]
    else:
        table_analysis = state["table_analysis"]

    # âœ… í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = HALLUCINATION_CHECK_PROMPT.format(
        selected_question=state["selected_question"],
        linearized_table=state["linearized_table"],
        ft_test_summary=str(state["ft_test_summary"]),
        table_analysis=table_analysis
    )

    # âœ… LLM í˜¸ì¶œ
    with st.spinner("Hallucination í‰ê°€ ì¤‘..."):
        response = llm.invoke(prompt)

    result = response.content.strip()

    # âœ… ê²°ê³¼ í•´ì„ ë° ìƒíƒœ ì—…ë°ì´íŠ¸
    if result.lower().startswith("reject"):
        decision = "reject"
        feedback = result[len("reject"):].strip(": ").strip()
        hallucination_reject_num += 1
        st.warning(f"âŒ Hallucination Check ê²°ê³¼: {decision}")
        st.info(f"ğŸ’¡ LLM Feedback: {feedback}")
        if "revised_analysis_history" not in state:
            state["revised_analysis_history"] = []
        state["revised_analysis_history"].append(table_analysis)
    else:
        decision = "accept"
        feedback = ""
        st.success(f"âœ… Hallucination Check ê²°ê³¼: {decision}")

    return {
        **state,
        "hallucination_check": decision,
        "feedback": feedback,
        "hallucination_reject_num": hallucination_reject_num
    }

streamlit_hallucination_check_node = RunnableLambda(streamlit_hallucination_check_node_fn)