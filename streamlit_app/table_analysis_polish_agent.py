import os
import openai
import streamlit as st

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableLambda

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3, openai_api_key=api_key)

POLISHING_PROMPT = {
    "í•œêµ­ì–´": """
ë‹¹ì‹ ì€ í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ëœ í•œêµ­ì–´ ë³´ê³ ì„œë¥¼ ë‹¤ë“¬ëŠ” ë¬¸ì²´ ì „ë¬¸ ì—ë””í„°ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” í†µê³„ ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½í•œ ì´ˆì•ˆì…ë‹ˆë‹¤.  
ë¬¸ì¥ì´ ë‹¨ì ˆì ì´ê±°ë‚˜(~í–ˆìŒ. ~í–ˆìŒ ë°˜ë³µ), í‘œí˜„ì´ ì¤‘ë³µë˜ê±°ë‚˜, ë¶ˆí•„ìš”í•œ ì¸ì‚¬ì´íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´, **ì˜ë¯¸ë¥¼ ë³€ê²½í•˜ì§€ ì•Šê³ ** ë” ì½ê¸° ì‰¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ë‹¤ë“¬ìœ¼ì„¸ìš”.

ğŸ¯ ë‹¤ìŒ ì§€ì¹¨ì„ ì—„ê²©íˆ ë”°ë¥´ì„¸ìš”:

1. **ë‚´ìš© ì¶”ê°€, ì‚­ì œ ê¸ˆì§€** â€” ìˆ˜ì¹˜ ê¸°ë°˜ì˜ ì›ë¬¸ ì •ë³´ì—ì„œ ë²—ì–´ë‚˜ëŠ” ìƒˆë¡œìš´ í•´ì„, ë°°ê²½ ì„¤ëª…, ì¸ê³¼ê´€ê³„ ìœ ì¶”ëŠ” ëª¨ë‘ ê¸ˆì§€
2. **'ìŒìŠ´ì²´' ìŠ¤íƒ€ì¼ ìœ ì§€** â€” ì˜ˆ: ~í–ˆìŒ, ~ë¡œ ë‚˜íƒ€ë‚¬ìŒ
3. **ì¸ì‚¬ì´íŠ¸ ì œê±°** â€” â€˜ê±´ê°•ì— ë¯¼ê°í•´ì„œâ€™, â€˜ì§ì ‘ ì˜í–¥ì„ ë°›ì•„ì„œâ€™ ë“± ì£¼ê´€ì  ì¶”ë¡ ì€ ëª¨ë‘ ì œê±°í•˜ê³ , í‘œë¡œë¶€í„° ë“œëŸ¬ë‚˜ëŠ” ì‚¬ì‹¤ë§Œ ìœ ì§€
4. **í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ í•­ëª©(ë³„í‘œ í¬í•¨ëœ ëŒ€ë¶„ë¥˜)**ë§Œ ë¬¸ì¥ì— í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸í•  ê²ƒ
5. **ì¤‘ë³µ í‘œí˜„ ì œê±° ë° ì—°ê²°** â€” ë™ì¼ ì˜ë¯¸ì˜ í‘œí˜„ ë°˜ë³µ("ë†’ê²Œ ë‚˜íƒ€ë‚¬ìŒ", "ê´€ì‹¬ì´ ë†’ì•˜ìŒ")ì€ í”¼í•˜ê³  ì—°ê²°ì–´ë¥¼ í†µí•´ ê°„ê²°í•˜ê²Œ ì •ë¦¬
6. **ë‹¨ì¡°ë¡œìš´ ë‚˜ì—´ í”¼í•˜ê¸°** â€” ~í–ˆìŒ. ~í–ˆìŒ. ë°˜ë³µí•˜ì§€ ë§ê³ , ë¬¸ì¥ êµ¬ì¡°ë¥¼ ë‹¤ì–‘í™”í•˜ê³  ì—°ê´€ëœ í•­ëª©ì€ í•œ ë¬¸ì¥ìœ¼ë¡œ ë¬¶ê¸°
7. **ë‹¤ì–‘í•œ í‘œí˜„ í˜¼ìš©** â€” ì•„ë˜ì™€ ê°™ì€ í‘œí˜„ì„ ì ì ˆíˆ ì„ì–´ ì‚¬ìš©í•  ê²ƒ:
   - ë‘ë“œëŸ¬ì§„ ê²½í–¥ ë³´ì˜€ìŒ
   - ëšœë ·í•œ ì°¨ì´ë¥¼ ë‚˜íƒ€ëƒˆìŒ
   - ìƒëŒ€ì ìœ¼ë¡œ ë†’ì€ ê°’ì„ ë³´ì˜€ìŒ
   - ê°€ì¥ ë†’ê²Œ í™•ì¸ëìŒ
8. **ë¶ˆí•„ìš”í•œ ì†Œë¶„ë¥˜ ë˜ëŠ” ëª¨ë“  ê·¸ë£¹ ë‚˜ì—´ ê¸ˆì§€** â€” ìš”ì•½ì€ íŠ¹ì§•ì ì¸ ê·¸ë£¹ ì¤‘ì‹¬ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•  ê²ƒ
9. **í‘œ ê¸°ë°˜ ì‚¬ì‹¤ë§Œ ìš”ì•½** â€” ìˆ˜ì¹˜ ê¸°ë°˜ ê²½í–¥ë§Œ ì „ë‹¬í•˜ê³ , í•´ì„ì€ í¬í•¨í•˜ì§€ ë§ ê²ƒ

ğŸ“ ê¸°ì¡´ ìš”ì•½:
{raw_summary}

---

ğŸ¯ ë‹¤ë“¬ì–´ì§„ ìµœì¢… ìš”ì•½ë¬¸:
""",
    "English": """
You are a stylistic editor for statistical summaries written in Korean.

Below is a draft summary of a statistical analysis.  
If the sentences are too choppy ("~í–ˆìŒ. ~í–ˆìŒ." repetition), redundant, or include subjective insights, rewrite them into a more readable style **without altering their meaning**.

ğŸ¯ Strictly follow these instructions:

1. **No additions or deletions** â€” Do not add new interpretations, background, or causal reasoning beyond the original numeric-based content.
2. **Keep declarative tone** â€” Use styles like: "~was observed", "~was shown"
3. **Remove speculative insights** â€” Phrases like â€œdue to health concernsâ€ or â€œbecause they were affectedâ€ must be removed; stick only to observable facts
4. **Only include categories with statistical significance (asterisked)** in the report
5. **Eliminate and connect duplicates** â€” Avoid repeating the same idea (e.g., â€œwas highâ€, â€œinterest was highâ€); connect with transitions
6. **Avoid monotonous structure** â€” Donâ€™t repeat "~was observed." repeatedly; vary structure and combine related findings into single sentences
7. **Use varied expressions** â€” Mix in phrases like:
   - Showed notable trend
   - Displayed clear difference
   - Exhibited relatively high values
   - Recorded the highest
8. **Avoid listing all subgroups** â€” Focus on concise summaries of characteristic groups
9. **Only report table-based facts** â€” Do not include interpretations; describe numeric trends only

ğŸ“ Original draft:
{raw_summary}

---

ğŸ¯ Polished final summary:
"""
}

def streamlit_sentence_polish_fn(state):
    lang = state.get("lang", "í•œêµ­ì–´")
    st.info("âœ… [Polish Agent] ë¬¸ì¥ ë‹¤ë“¬ê¸° ì‹œì‘" if lang == "í•œêµ­ì–´" else "âœ… [Polish Agent] Start sentence polishing")

    hallucination_reject_num = state["hallucination_reject_num"]

    raw_summary = state["table_analysis"] if hallucination_reject_num == 0 else state["revised_analysis"]

    with st.spinner("LLMì´ ë¬¸ì¥ì„ ë‹¤ë“¬ëŠ” ì¤‘..." if lang == "í•œêµ­ì–´" else "LLM is polishing the summary..."):
        response = llm.invoke(POLISHING_PROMPT[lang].format(raw_summary=raw_summary))

    polishing_result = response.content.strip()

    st.text("### âœ… ìµœì¢… ë³´ê³ ì„œ" if lang == "í•œêµ­ì–´" else "### âœ… Final Report")
    st.success("ğŸ‰ ë‹¤ë“¬ì–´ì§„ ìµœì¢… ìš”ì•½ë¬¸:" if lang == "í•œêµ­ì–´" else "ğŸ‰ Polished Final Summary:")
    st.text(polishing_result)

    return {**state, "polishing_result": polishing_result}

streamlit_sentence_polish_node = RunnableLambda(streamlit_sentence_polish_fn)