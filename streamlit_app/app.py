import streamlit as st

# ‚úÖ Ï†úÏùº Î®ºÏ†Ä ÌéòÏù¥ÏßÄ ÏÑ§Ï†ï
st.set_page_config(page_title="Table Analysis Agent", layout="wide")
import io
import os
import traceback
import logging

# üåê Îã§Íµ≠Ïñ¥ ÌÖçÏä§Ìä∏ (Ìïú-ÏòÅ)
lang = st.sidebar.radio("üåê Language", ["English", "ÌïúÍµ≠Ïñ¥"])

TEXT = {
    "page_selector": {
        "English": ["üìñ Service Introduction", "üß™ Run Analysis"],
        "ÌïúÍµ≠Ïñ¥": ["üìñ ÏÑúÎπÑÏä§ ÏÜåÍ∞ú", "üß™ Î∂ÑÏÑù Ïã§Ìñâ"]
    },
    "run_page": {
        "title": {
            "ÌïúÍµ≠Ïñ¥": "üìä Table Statistical Analysis Multi-Agent",
            "English": "üìä Table Statistical Analysis Multi-Agent"
        },
        "filename_warning": {
            "ÌïúÍµ≠Ïñ¥": "‚ö†Ô∏è **ÏóÖÎ°úÎìúÌï† ÌååÏùº Ïù¥Î¶ÑÏùÄ Î∞òÎìúÏãú ÏòÅÎ¨∏ ÎòêÎäî Ïà´ÏûêÎ°ú Íµ¨ÏÑ±ÎêòÏñ¥Ïïº Ìï©ÎãàÎã§.**",
            "English": "‚ö†Ô∏è **The uploaded file name must consist only of English letters or numbers.**"
        },
        "filename_format": {
            "ÌïúÍµ≠Ïñ¥": "ÌïúÍ∏Ä, Í≥µÎ∞±, ÌäπÏàòÎ¨∏ÏûêÍ∞Ä Ìè¨Ìï®Îêú Í≤ΩÏö∞ ÏóÖÎ°úÎìúÍ∞Ä Ïã§Ìå®Ìï† Ïàò ÏûàÏäµÎãàÎã§. Ïòà: `data_2024.xlsx` ‚úÖ",
            "English": "If your file name includes Korean, spaces, or special characters, upload may fail. Example: `data_2024.xlsx` ‚úÖ"
        },
        "flow_reminder": {
            "ÌïúÍµ≠Ïñ¥": "- Excel ÌÜµÍ≥ÑÌëú Í∏∞Î∞ò Î∂ÑÏÑù ÏûêÎèôÌôî\n- Upload File ‚Üí Parsing ‚Üí Hypothesis ‚Üí Numeric Analysis ‚Üí Table Analysis ‚Üí Hallucination Check ‚Üí Revision ‚Üí Polishing",
            "English": "- Automated analysis of Excel-based summary tables\n- Upload File ‚Üí Parsing ‚Üí Hypothesis ‚Üí Numeric Analysis ‚Üí Table Analysis ‚Üí Hallucination Check ‚Üí Revision ‚Üí Polishing"
        },
        "sidebar_file_upload": {
            "ÌïúÍµ≠Ïñ¥": "1Ô∏è‚É£ Î∂ÑÏÑùÏö© Excel ÌååÏùº ÏóÖÎ°úÎìú (ÌÜµÍ≥ÑÌëú)",
            "English": "1Ô∏è‚É£ Upload Excel File for Analysis (Summary Table)"
        },
        "sidebar_raw_upload": {
            "ÌïúÍµ≠Ïñ¥": "2Ô∏è‚É£ ÏõêÏãú Îç∞Ïù¥ÌÑ∞ Excel ÌååÏùº ÏóÖÎ°úÎìú (Raw DATA, Î≥ÄÏàò, ÏΩîÎî©Í∞ÄÏù¥Îìú, Î¨∏Ìï≠ Ìè¨Ìï®)",
            "English": "2Ô∏è‚É£ Upload Raw Data Excel File (Raw DATA, variables, code guide, questions)"
        },
        "sidebar_mode": {
            "ÌïúÍµ≠Ïñ¥": "3Ô∏è‚É£ Î∂ÑÏÑù Î∞©Ïãù ÏÑ†ÌÉù",
            "English": "3Ô∏è‚É£ Select Analysis Mode"
        },
        "mode_options": {
            "English": ["Single Question - Manual Selection", "Batch All Questions - Full Auto Analysis"],
            "ÌïúÍµ≠Ïñ¥": ["Îã®Ïùº ÏßàÎ¨∏ ÏÑ†ÌÉù - ÏßÅÏ†ë ÏÑ†ÌÉù", "Ï†ÑÏ≤¥ ÏßàÎ¨∏ batch - Ï†ÑÏ≤¥ ÏûêÎèô Î∂ÑÏÑù"]
        },
        "select_question_header": {
            "ÌïúÍµ≠Ïñ¥": "4Ô∏è‚É£ Î∂ÑÏÑùÌï† ÏßàÎ¨∏ ÏÑ†ÌÉù",
            "English": "4Ô∏è‚É£ Select Question for Analysis"
        },
        "select_question_info": {
            "ÌïúÍµ≠Ïñ¥": "üìã ÏóÖÎ°úÎìúÌïú Î∂ÑÏÑùÏö© Excel ÌååÏùºÏùò ÏßàÎ¨∏ Î™©Î°ùÏûÖÎãàÎã§. Î∂ÑÏÑùÌï† ÏßàÎ¨∏ÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî.",
            "English": "üìã This is a list of questions from the uploaded Excel. Please select one for analysis."
        },
        "no_valid_questions": {
            "ÌïúÍµ≠Ïñ¥": "‚ùå Ïú†Ìö®Ìïú ÏßàÎ¨∏ ÌÖçÏä§Ìä∏Í∞Ä ÏóÜÏäµÎãàÎã§.",
            "English": "‚ùå No valid question text found."
        },
        "selectbox_label": {
            "ÌïúÍµ≠Ïñ¥": "ÏßàÎ¨∏ Î™©Î°ù",
            "English": "Question List"
        },
        "selected_question": {
            "ÌïúÍµ≠Ïñ¥": "‚úÖ ÏÑ†ÌÉùÎêú ÏßàÎ¨∏:",
            "English": "‚úÖ Selected Question:"
        },
        "run_button": {
            "ÌïúÍµ≠Ïñ¥": "üöÄ Î∂ÑÏÑù ÏãúÏûë",
            "English": "üöÄ Start Analysis"
        },
        "error_missing_file": {
            "ÌïúÍµ≠Ïñ¥": "‚ùó Î∂ÑÏÑùÏö© Excel ÌååÏùºÏùÑ Î®ºÏ†Ä ÏóÖÎ°úÎìúÌïòÏÑ∏Ïöî.",
            "English": "‚ùó Please upload the analysis Excel file first."
        },
        "error_missing_raw": {
            "ÌïúÍµ≠Ïñ¥": "‚ùó ÏõêÏãú Îç∞Ïù¥ÌÑ∞ Excel ÌååÏùºÎèÑ Î∞òÎìúÏãú ÏóÖÎ°úÎìúÌï¥Ïïº Ìï©ÎãàÎã§.",
            "English": "‚ùó You must also upload the raw data Excel file."
        },
        "analyzing_spinner": {
            "ÌïúÍµ≠Ïñ¥": "Î∂ÑÏÑù Ï§ë... Ïû†ÏãúÎßå Í∏∞Îã§Î†§Ï£ºÏÑ∏Ïöî",
            "English": "Analyzing... please wait a moment"
        },
        "analysis_done": {
            "ÌïúÍµ≠Ïñ¥": "üéâ Î∂ÑÏÑù ÏôÑÎ£å!",
            "English": "üéâ Analysis complete!"
        },
        "final_result_title": {
            "ÌïúÍµ≠Ïñ¥": "### üîç ÏµúÏ¢Ö ÏöîÏïΩ Í≤∞Í≥º",
            "English": "### üîç Final Summary Result"
        },
        "no_result_warning": {
            "ÌïúÍµ≠Ïñ¥": "‚ö†Ô∏è ÏµúÏ¢Ö Í≤∞Í≥ºÍ∞Ä ÏÉùÏÑ±ÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.",
            "English": "‚ö†Ô∏è No final result was generated."
        },
        "upload_table_error": {
            "ÌïúÍµ≠Ïñ¥": "‚ùå ÏóÖÎ°úÎìúÎêú ÌÜµÍ≥ÑÌëú ÌååÏùºÏóêÏÑú ÌÖåÏù¥Î∏îÏùÑ ÏùΩÎäî Ï§ë Ïò§Î•ò Î∞úÏÉù:",
            "English": "‚ùå Error reading tables from uploaded summary Excel file:"
        },
        "raw_file_processing_error": {
            "ÌïúÍµ≠Ïñ¥": "‚ùå ÏõêÏãú Îç∞Ïù¥ÌÑ∞ ÌååÏùº Ï≤òÎ¶¨ Ïò§Î•ò:",
            "English": "‚ùå Error processing raw data file:"
        },
        "workflow_build_error": {
            "ÌïúÍµ≠Ïñ¥": "‚ùå ÏõåÌÅ¨ÌîåÎ°úÏö∞ ÎπåÎìú Ï§ë Ïò§Î•ò Î∞úÏÉù:",
            "English": "‚ùå Error occurred while building the workflow:"
        },
        "workflow_execute_error": {
            "ÌïúÍµ≠Ïñ¥": "‚ùå Î∂ÑÏÑù Ïã§Ìñâ Ï§ë Ïò§Î•ò Î∞úÏÉù:",
            "English": "‚ùå Error occurred during workflow execution:"
        },
        "unexpected_error": {
            "ÌïúÍµ≠Ïñ¥": "‚ùå ÏòàÏÉÅÏπò Î™ªÌïú Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§:",
            "English": "‚ùå An unexpected error occurred:"
        },
        "file_uploader_table_label": {
            "ÌïúÍµ≠Ïñ¥": "üì• Î∂ÑÏÑùÏö© Excel ÌååÏùºÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
            "English": "üì• Select an Excel file for analysis"
        },
        "file_uploader_raw_label": {
            "ÌïúÍµ≠Ïñ¥": "üì• ÏõêÏãú Îç∞Ïù¥ÌÑ∞ Excel ÌååÏùºÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
            "English": "üì• Select a raw data Excel file"
        },
        "batch_analysis_info": {
            "ÌïúÍµ≠Ïñ¥": "üìå Ï†ÑÏ≤¥ batch Î∂ÑÏÑùÏùÑ ÏàòÌñâÌï©ÎãàÎã§. Í∞Å ÏßàÎ¨∏ÏùÄ ÏûêÎèô Î∂ÑÏÑùÎê©ÎãàÎã§.",
            "English": "üìå Batch analysis will be performed for all questions automatically."
        },
        "missing_question_warning": {
            "ÌïúÍµ≠Ïñ¥": "‚ö†Ô∏è ÏßàÎ¨∏ ÌÖçÏä§Ìä∏ ÎàÑÎùΩ:",
            "English": "‚ö†Ô∏è Missing question text:"
        }
    },
    "intro_title": {
        "ÌïúÍµ≠Ïñ¥": "üìñ Table Analysis Agent ÏÜåÍ∞ú",
        "English": "üìñ Introduction to Table Analysis Agent"
    },
    "agent_overview": {
        "ÌïúÍµ≠Ïñ¥": """
Ïù¥ ÏÑúÎπÑÏä§Îäî ÌÜµÍ≥Ñ Ï°∞ÏÇ¨ Í≤∞Í≥ºÌëúÎ•º Í∏∞Î∞òÏúºÎ°ú ÏûêÎèôÏúºÎ°ú Îç∞Ïù¥ÌÑ∞Î•º Î∂ÑÏÑùÌïòÍ≥† ÏöîÏïΩÌï¥Ï£ºÎäî Î©ÄÌã∞ ÏóêÏù¥Ï†ÑÌä∏ Í∏∞Î∞ò ÌîåÎû´ÌèºÏûÖÎãàÎã§.

### ‚úÖ ÏÇ¨Ïö©ÎêòÎäî Ï£ºÏöî ÏóêÏù¥Ï†ÑÌä∏ Íµ¨ÏÑ±:
- üì• **Table Parser**: ÏóÖÎ°úÎìúÌïú ÏóëÏÖÄ ÌååÏùºÏóêÏÑú ÏÑ§Î¨∏ Î¨∏Ìï≠Í≥º ÌÜµÍ≥Ñ ÌÖåÏù¥Î∏îÏùÑ ÏûêÎèôÏúºÎ°ú ÌååÏã±
- ‚úèÔ∏è **Hypothesis Generator**: ÌÖåÏù¥Î∏îÏóê Í∏∞Î∞òÌïú Ï¥àÍ∏∞ Î∂ÑÏÑù Í∞ÄÏÑ§ ÏûêÎèô ÏÉùÏÑ±
- üß≠ **Test Type Decision**: ÌÜµÍ≥ÑÏ†Å Í≤ÄÏ†ï Î∞©Ïãù(F-test, T-test Îì±) ÏûêÎèô ÌåêÎã®
- üìä **F/T-Test Analyzer**: ÏàòÏπò Îç∞Ïù¥ÌÑ∞Î•º Í∏∞Î∞òÏúºÎ°ú ÌÜµÍ≥ÑÏ†Å Ïú†ÏùòÏÑ± Í≤ÄÏ†ï ÏàòÌñâ
- üìå **Anchor Extractor**: ÌÖåÏù¥Î∏îÏóêÏÑú Í∞ÄÏû• ÎëêÎìúÎü¨ÏßÑ ÎåÄÎ∂ÑÎ•ò Ìï≠Î™©(anchor)ÏùÑ Ï∂îÏ∂ú
- üìù **Table Analyzer**: ÏàòÏπòÏôÄ anchorÎ•º Î∞îÌÉïÏúºÎ°ú Ï¥àÍ∏∞ ÏöîÏïΩ Î≥¥Í≥†ÏÑú ÏÉùÏÑ±
- üß† **Hallucination Checker**: Î≥¥Í≥†ÏÑúÏùò Ïò§Î•ò Ïó¨Î∂Ä ÌåêÎã® (LLM Í∏∞Î∞ò Í≤ÄÏ¶ù)
- üîÅ **Reviser**: ÏûòÎ™ªÎêú ÏöîÏïΩÏùÑ ÌîºÎìúÎ∞± Í∏∞Î∞òÏúºÎ°ú ÏàòÏ†ï
- üíÖ **Polisher**: ÏµúÏ¢Ö ÏöîÏïΩÏùÑ ÏûêÏó∞Ïä§ÎüΩÍ≥† Í∞ÑÍ≤∞ÌïòÍ≤å Îã§Îì¨Îäî Ïó≠Ìï†
""",
        "English": """
This service is a multi-agent platform that analyzes and summarizes statistical survey tables using AI agents.

### ‚úÖ Main agents used:
- üì• **Table Parser**: Parses survey questions and summary tables from the uploaded Excel
- ‚úèÔ∏è **Hypothesis Generator**: Automatically generates initial hypotheses based on the table
- üß≠ **Test Type Decision**: Determines appropriate statistical tests (F-test, T-test, etc.)
- üìä **F/T-Test Analyzer**: Performs statistical significance testing based on numerical data
- üìå **Anchor Extractor**: Identifies salient categories (anchors) within the table
- üìù **Table Analyzer**: Drafts initial summary based on stats and anchors
- üß† **Hallucination Checker**: Detects errors in LLM-generated reports
- üîÅ **Reviser**: Fixes inaccurate summaries based on LLM feedback
- üíÖ **Polisher**: Refines the final summary to be fluent and concise
"""
    },
    "usage_guide": {
        "ÌïúÍµ≠Ïñ¥": """
1. ÏÇ¨Ïù¥ÎìúÎ∞îÏóêÏÑú **Î∂ÑÏÑùÏö© ÌÜµÍ≥ÑÌëú ÌååÏùº**Í≥º **ÏõêÏãú Îç∞Ïù¥ÌÑ∞ ÌååÏùº**ÏùÑ ÏóÖÎ°úÎìúÌï©ÎãàÎã§.  
    - Îëê ÌååÏùºÏùÄ Î™®Îëê **ÏóëÏÖÄ(xlsx, xls)** ÌòïÏãùÏù¥Î©∞ ÌååÏùºÎ™ÖÏùÄ **ÏòÅÎ¨∏** ÌòïÌÉúÏó¨Ïïº Ìï©ÎãàÎã§.
    - Î∂ÑÏÑùÏö© ÌååÏùºÏóêÎäî ÏÑ§Î¨∏ Î¨∏Ìï≠Î≥Ñ ÌÜµÍ≥Ñ ÏöîÏïΩ ÌÖåÏù¥Î∏îÏù¥ Ìè¨Ìï®ÎêòÏñ¥ ÏûàÏñ¥Ïïº ÌïòÎ©∞, Í∞Å ÏãúÌä∏ Ïù¥Î¶ÑÏùÄ Î¨∏Ìï≠ ÌÇ§(Ïòà: Q1, SQ3 Îì±)Î°ú ÎêòÏñ¥ ÏûàÏñ¥Ïïº Ìï©ÎãàÎã§.  
    - ÏõêÏãú Îç∞Ïù¥ÌÑ∞ ÌååÏùºÏóêÎäî ÏµúÏÜåÌïú Îã§Ïùå ÏãúÌä∏Í∞Ä Ìè¨Ìï®ÎêòÏñ¥Ïïº Ìï©ÎãàÎã§: `DATA`, `DEMO`
        - `DATA`: Í∞Å Î¨∏Ìï≠Îì§(A1, A1_1, ...)Ïóê ÎåÄÌïú ÏÑ§Î¨∏ Ï°∞ÏÇ¨ Í≤∞Í≥º + ÌëúÎ≥∏ ÌäπÏÑ±Î≥ÑÎ°ú Ï†ÑÏ≤òÎ¶¨Í∞Ä Îêú Î≥ÄÏàò(DEMO1, DEMO2, ...)
        - `DEMO`: ÌëúÎ≥∏ ÌäπÏÑ±Î≥Ñ Î≥ÄÏàòÎì§(DEMO1, DEMO2, ...)Ïóê ÎåÄÌïú ÏÑ§Î™Ö
    - ÌÜµÍ≥ÑÌëúÎäî Î≤îÏ£ºÌòï Í∞íÏóê ÎåÄÌïú ÎπàÎèÑ Î∞è ÎπÑÏú®ÏùÑ Ìè¨Ìï®ÌïòÍ≥† ÏûàÏñ¥Ïïº ÌïòÎ©∞, Í≤∞Ï∏°Í∞íÏùÄ Ï†úÍ±∞ÎêòÏñ¥ ÏûàÏñ¥Ïïº Ìï©ÎãàÎã§.
2. Î∂ÑÏÑù Î∞©ÏãùÏúºÎ°ú **Îã®Ïùº Î¨∏Ìï≠ Î∂ÑÏÑù** ÎòêÎäî **Ï†ÑÏ≤¥ ÏûêÎèô Î∂ÑÏÑù(batch)** Ï§ë ÌïòÎÇòÎ•º ÏÑ†ÌÉùÌï©ÎãàÎã§.
3. [üöÄ Î∂ÑÏÑù ÏãúÏûë] Î≤ÑÌäºÏùÑ ÌÅ¥Î¶≠ÌïòÎ©¥, ÏúÑÏùò ÏóêÏù¥Ï†ÑÌä∏Îì§Ïù¥ ÏàúÏ∞®Ï†ÅÏúºÎ°ú Ïã§ÌñâÎê©ÎãàÎã§.
4. Î∂ÑÏÑù Í≤∞Í≥ºÎäî Îã®Í≥ÑÎ≥ÑÎ°ú Ï∂úÎ†•ÎêòÎ©∞, ÎßàÏßÄÎßâÏóêÎäî polishedÎêú ÏµúÏ¢Ö Î≥¥Í≥†ÏÑúÎ•º ÌôïÏù∏Ìï† Ïàò ÏûàÏäµÎãàÎã§.
5. ÌïÑÏöî Ïãú ÏµúÏ¢Ö Î≥¥Í≥†ÏÑúÎ•º Î≥µÏÇ¨ÌïòÏó¨ Ìé∏ÏßëÌïòÍ±∞ÎÇò Ïô∏Î∂Ä Î≥¥Í≥†ÏÑúÎ°ú ÌôúÏö©ÌïòÏÑ∏Ïöî.
""",
        "English": """
1. Upload the **statistical summary table** and the **raw data file** from the sidebar.  
    - Both files must be in **Excel format (xlsx, xls)**, and filenames should consist of **English characters only**.
    - The summary table should contain tabulated survey results, with each sheet named using the question key (e.g., Q1, SQ3).
    - The raw data file must include at least the following sheets: `DATA`, `DEMO`
        - `DATA`: Contains individual survey responses (e.g., A1, A1_1, ...) and preprocessed demographic variables (e.g., DEMO1, DEMO2, ...)
        - `DEMO`: Descriptions of the demographic variables (DEMO1, DEMO2, ...)
    - The summary tables must include frequency and percentage data for categorical variables and exclude missing values.
2. Choose either **single-question analysis** or **batch analysis for all questions**.
3. Click the [üöÄ Start Analysis] button to run each agent in sequence.
4. The results will be shown step-by-step, and the final polished report will appear at the end.
5. Copy and edit the final report as needed for documentation or reporting.
"""
    },
    "usage_guide_title": {
        "ÌïúÍµ≠Ïñ¥": "### üõ†Ô∏è ÏÇ¨Ïö© Î∞©Î≤ï ÏïàÎÇ¥:",
        "English": "### üõ†Ô∏è How to Use This Service:"
    },
    "mermaid_diagram_title": {
        "ÌïúÍµ≠Ïñ¥": "### üß† Î©ÄÌã∞ÏóêÏù¥Ï†ÑÌä∏ Î∂ÑÏÑù ÌùêÎ¶ÑÎèÑ (Mermaid Diagram)",
        "English": "### üß† Multi-Agent Workflow Diagram (Mermaid)"
    }
}

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

try:
    from dotenv import load_dotenv
    # Try importing your custom modules with error handling
    try:
        from streamlit_table_workflow_graph import build_table_graph
        from streamlit_table_parser import load_survey_tables
    except ImportError as e:
        st.error(f"‚ùå Failed to import required modules: {e}")
        logger.error(f"Import error: {e}")
        st.stop()
except ImportError as e:
    st.error(f"‚ùå Failed to import dotenv: {e}")
    logger.error(f"Dotenv import error: {e}")
    st.stop()

# üîë ÌôòÍ≤Ω Î≥ÄÏàò Î°úÎî© (.env Î°úÏª¨ + st.secrets Î∞∞Ìè¨Ïö©)
try:
    load_dotenv()
    # Log API key status (without revealing the key)
    if "OPENAI_API_KEY" in os.environ:
        logger.info("OPENAI_API_KEY found in environment variables")
    
    if "OPENAI_API_KEY" in st.secrets:
        os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
        logger.info("OPENAI_API_KEY loaded from st.secrets")
    else:
        logger.warning("OPENAI_API_KEY not found in st.secrets")
        
    # Verify API key is set
    if "OPENAI_API_KEY" not in os.environ:
        st.warning("‚ö†Ô∏è OPENAI_API_KEY not set. Some features may not work.")
        logger.warning("OPENAI_API_KEY not set in environment")
except Exception as e:
    st.error(f"‚ùå Error loading environment variables: {e}")
    logger.error(f"Environment error: {e}")

def normalize_key(key: str) -> str:
    return key.replace("-", "_").lower()

def main():
    try:

        page = st.sidebar.radio("üìÑ Page", TEXT["page_selector"][lang])

        if page == TEXT["page_selector"][lang][0]:
            st.title(TEXT["intro_title"][lang])
            st.markdown(TEXT["agent_overview"][lang])
            st.markdown(TEXT["usage_guide_title"][lang])
            st.markdown(TEXT["usage_guide"][lang])
            st.markdown(TEXT["mermaid_diagram_title"][lang])
            mermaid_code = """
            <div class="mermaid">
            graph TD
                A[üì• table_parser] --> B[‚úèÔ∏è hypothesis_generate_node]
                B --> C[üß≠ test_decision_node]
                C --> D[üìä FT_anlysis_node]
                D --> E[üìå get_anchor_node]
                E --> F[üìù table_analyzer]
                F --> G[üß† hallucination_check_node]

                G -- accept --> H[üíÖ sentence_polish_node]
                G -- reject < 4 --> I[üîÅ revise_table_analysis]
                I --> G
                G -- reject ‚â• 4 --> H

                H --> Z([‚úÖ END])
            </div>
            <script type="module">
            import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
            mermaid.initialize({ startOnLoad: true });
            </script>
            """
            st.components.v1.html(mermaid_code, height=800)
            return

        if page == TEXT["page_selector"][lang][1]:
            st.title(TEXT["run_page"]["title"][lang])

            st.info(TEXT["run_page"]["filename_warning"][lang])
            st.markdown(TEXT["run_page"]["filename_format"][lang])

            st.markdown(TEXT["run_page"]["flow_reminder"][lang])

            # ‚úÖ ÏÇ¨Ïù¥ÎìúÎ∞î: ÏóÖÎ°úÎìú
            with st.sidebar:
                st.header(TEXT["run_page"]["sidebar_file_upload"][lang])
                uploaded_file = st.file_uploader(TEXT["run_page"]["file_uploader_table_label"][lang], type=None)

                st.header(TEXT["run_page"]["sidebar_raw_upload"][lang])
                raw_data_file = st.file_uploader(TEXT["run_page"]["file_uploader_raw_label"][lang], type=None, key="raw_data")

                st.header(TEXT["run_page"]["sidebar_mode"][lang])
                analysis_type = st.radio(
                    "Î∂ÑÏÑù Î∞©Ïãù",
                    TEXT["run_page"]["mode_options"][lang],
                    index=0
                )
                # For both languages, "Single Question" is always first
                if lang == "ÌïúÍµ≠Ïñ¥":
                    analysis_type_flag = analysis_type.startswith("Îã®Ïùº")
                else:
                    analysis_type_flag = analysis_type.startswith("Single")

            selected_question_key = None
            selected_table = None
            tables = None
            question_texts = None
            question_keys = None

            if uploaded_file:
                try:
                    logger.info("Loading tables from uploaded file")
                    file_bytes = io.BytesIO(uploaded_file.read())
                    # Reset file pointer for future use
                    uploaded_file.seek(0)

                    tables, question_texts, question_keys = load_survey_tables(file_bytes)
                    logger.info(f"Successfully loaded {len(tables)} tables")
                except Exception as e:
                    logger.error(f"Error loading tables: {traceback.format_exc()}")
                    st.error(f"{TEXT['run_page']['upload_table_error'][lang]} {str(e)}")
                    st.stop()

                if analysis_type_flag and tables is not None:
                    st.subheader(TEXT["run_page"]["select_question_header"][lang])
                    st.info(TEXT["run_page"]["select_question_info"][lang])

                    normalized_question_texts = {normalize_key(k): v for k, v in question_texts.items()}
                    options = []
                    for key in question_keys:
                        norm_key = normalize_key(key)
                        if norm_key in normalized_question_texts:
                            label = normalized_question_texts[norm_key]
                            options.append(f"[{key}] {label}")
                        else:
                            st.warning(f"{TEXT['run_page']['missing_question_warning'][lang]} '{key}'")
                            logger.warning(f"Missing question text for key: {key}")

                    if not options:
                        st.error(TEXT["run_page"]["no_valid_questions"][lang])
                        logger.error("No valid question texts found")
                        st.stop()

                    selected_option = st.selectbox(TEXT["run_page"]["selectbox_label"][lang], options)
                    selected_index = options.index(selected_option)
                    selected_question_key = question_keys[selected_index]
                    selected_table = tables[selected_question_key]

                    st.success(f"{TEXT['run_page']['selected_question'][lang]} {question_texts.get(selected_question_key, selected_question_key)}")
                    st.dataframe(selected_table.head(), use_container_width=True)
                elif not analysis_type_flag:
                    st.info(TEXT["run_page"]["batch_analysis_info"][lang])

            run = st.button(TEXT["run_page"]["run_button"][lang], use_container_width=True)

            if run:
                if uploaded_file is None:
                    st.error(TEXT["run_page"]["error_missing_file"][lang])
                    logger.error("Analysis started without uploaded file")
                    st.stop()
                if raw_data_file is None:
                    st.error(TEXT["run_page"]["error_missing_raw"][lang])
                    logger.error("Analysis started without raw data file")
                    st.stop()

                try:
                    logger.info("Reading raw data file")
                    raw_data_stream = io.BytesIO(raw_data_file.read())
                    # Reset file pointer for future use
                    raw_data_file.seek(0)
                except Exception as e:
                    logger.error(f"Raw data file processing error: {traceback.format_exc()}")
                    st.error(f"{TEXT['run_page']['raw_file_processing_error'][lang]} {str(e)}")
                    st.stop()

                try:
                    logger.info("Building table graph workflow")
                    workflow = build_table_graph()
                except Exception as e:
                    logger.error(f"Error building workflow: {traceback.format_exc()}")
                    st.error(f"{TEXT['run_page']['workflow_build_error'][lang]} {str(e)}")
                    st.stop()

                init_state = {
                    "analysis_type": analysis_type_flag,
                    "uploaded_file": io.BytesIO(uploaded_file.read()),
                    "raw_data_file": raw_data_stream,
                    "lang": lang
                }

                if analysis_type_flag and selected_question_key is not None:
                    init_state["selected_key"] = selected_question_key

                try:
                    logger.info("Invoking workflow")
                    with st.spinner(TEXT["run_page"]["analyzing_spinner"][lang]):
                        result = workflow.invoke(init_state)
                    logger.info("Workflow completed successfully")
                except Exception as e:
                    logger.error(f"Workflow execution error: {traceback.format_exc()}")
                    st.error(f"{TEXT['run_page']['workflow_execute_error'][lang]} {str(e)}")
                    st.stop()

                st.success(TEXT["run_page"]["analysis_done"][lang])

                if "polishing_result" in result:
                    st.markdown(TEXT["run_page"]["final_result_title"][lang])
                    st.text_area("Polished Report", result["polishing_result"], height=300)
                else:
                    st.warning(TEXT["run_page"]["no_result_warning"][lang])
                    logger.warning("No polishing_result in workflow output")
    except Exception as e:
        logger.error(f"Unhandled exception: {traceback.format_exc()}")
        st.error(f"{TEXT['run_page']['unexpected_error'][lang]} {str(e)}")

if __name__ == "__main__":
    main()