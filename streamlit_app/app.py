import streamlit as st

from text_dictionary import TEXT

# âœ… ì œì¼ ë¨¼ì € í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Table Analysis Agent", layout="wide")
import io
import os
import traceback
import logging

# ğŸŒ ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸ (í•œ-ì˜)
lang = st.sidebar.radio("ğŸŒ Language", ["English", "í•œêµ­ì–´"], index=1)

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

try:
    from dotenv import load_dotenv
    # Try importing your custom modules with error handling
    try:
        from table_analysis_graph import build_table_graph
        from stable_analysis_table_parser import load_survey_tables
        from planner_graph import planner_graph
    except ImportError as e:
        st.error(f"âŒ Failed to import required modules: {e}")
        logger.error(f"Import error: {e}")
        st.stop()
except ImportError as e:
    st.error(f"âŒ Failed to import dotenv: {e}")
    logger.error(f"Dotenv import error: {e}")
    st.stop()

# ğŸ”‘ í™˜ê²½ ë³€ìˆ˜ ë¡œë”© (.env ë¡œì»¬ + st.secrets ë°°í¬ìš©)
try:
    load_dotenv()
    # Log API key status (without revealing the key)
    if "OPENAI_API_KEY" in os.environ:
        logger.info("OPENAI_API_KEY found in environment variables")
    
    if "OPENAI_API_KEY" in st.secrets:
        os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
        logger.info("OPENAI_API_KEY loaded from st.secrets")
    else:
        logger.warning("OPENAI_API_KEY not found in st.secrets")
        
    # Verify API key is set
    if "OPENAI_API_KEY" not in os.environ:
        st.warning("âš ï¸ OPENAI_API_KEY not set. Some features may not work.")
        logger.warning("OPENAI_API_KEY not set in environment")
except Exception as e:
    st.error(f"âŒ Error loading environment variables: {e}")
    logger.error(f"Environment error: {e}")

def normalize_key(key: str) -> str:
    return key.replace("-", "_").lower()

def main():
    try:
        page = st.sidebar.radio("ğŸ“„ Page", TEXT["page_selector"][lang])

        ######### ê¸°ë³¸ ë©”ì¸ í™”ë©´ #########
        if page == TEXT["page_selector"][lang][0]:
            st.title(TEXT["intro_title"][lang])
            st.markdown(TEXT["agent_overview"][lang])
            st.markdown(TEXT["usage_guide_title"][lang])
            st.markdown(TEXT["usage_guide"][lang])
            st.markdown(TEXT["mermaid_diagram_title"][lang])
            mermaid_code = """
            <div class="mermaid">
            graph TD
                A[ğŸ“¥ table_parser] --> B[âœï¸ hypothesis_generate_node]
                B --> C[ğŸ§­ test_decision_node]
                C --> D[ğŸ“Š FT_anlysis_node]
                D --> E[ğŸ“Œ get_anchor_node]
                E --> F[ğŸ“ table_analyzer]
                F --> G[ğŸ§  hallucination_check_node]

                G -- accept --> H[ğŸ’… sentence_polish_node]
                G -- reject < 4 --> I[ğŸ” revise_table_analysis]
                I --> G
                G -- reject â‰¥ 4 --> H

                H --> Z([âœ… END])
            </div>
            <script type="module">
            import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
            mermaid.initialize({ startOnLoad: true });
            </script>
            """
            st.components.v1.html(mermaid_code, height=800)
            return

        ######### í†µê³„ ì„¤ê³„ ë„ìš°ë¯¸ í˜ì´ì§€ #########
        if page == TEXT["page_selector"][lang][2]:
            st.title(TEXT["planner_page"]["title"][lang])
            st.markdown(TEXT["planner_page"]["description"][lang])

            topic = st.text_input(
                TEXT["planner_page"]["survey_topic"][lang],
                placeholder=TEXT["planner_page"]["survey_topic_ph"][lang]
            )
            objective_input = st.text_area(
                TEXT["planner_page"]["research_objectives"][lang],
                placeholder=TEXT["planner_page"]["research_objectives_ph"][lang]
            )

            if st.button(TEXT["planner_page"]["generate"][lang]):
                if not topic:
                    st.warning("ğŸ“ ì¡°ì‚¬ ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”." if lang == "í•œêµ­ì–´" else "ğŸ“ Please enter a survey topic.")
                    st.stop()

                with st.spinner("ğŸ” ì„¤ë¬¸ì¡°ì‚¬ ì„¤ê³„ ì¤‘..." if lang == "í•œêµ­ì–´" else "ğŸ” Planning your survey..."):
                    planner_result = planner_graph.invoke({
                        "topic": topic,
                        "objective": objective_input,
                        "lang": lang
                    })

                st.success("âœ… ì„¤ë¬¸ì¡°ì‚¬ ì„¤ê³„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!" if lang == "í•œêµ­ì–´" else "âœ… Survey planning completed!")
            return

        ######### í…Œì´ë¸” ë¶„ì„ ë³´ê³ ì„œ ì‘ì„± ì‹¤í–‰ í™”ë©´ #########
        if page == TEXT["page_selector"][lang][1]:
            st.title(TEXT["run_page"]["title"][lang])

            st.info(TEXT["run_page"]["filename_warning"][lang])
            st.markdown(TEXT["run_page"]["filename_format"][lang])

            st.markdown(TEXT["run_page"]["flow_reminder"][lang])

            # âœ… ì‚¬ì´ë“œë°”: ì—…ë¡œë“œ
            with st.sidebar:
                st.header(TEXT["run_page"]["sidebar_file_upload"][lang])
                uploaded_file = st.file_uploader(TEXT["run_page"]["file_uploader_table_label"][lang], type=None)

                st.header(TEXT["run_page"]["sidebar_raw_upload"][lang])
                raw_data_file = st.file_uploader(TEXT["run_page"]["file_uploader_raw_label"][lang], type=None, key="raw_data")

                st.header(TEXT["run_page"]["sidebar_mode"][lang])
                analysis_type = st.radio(
                    "ë¶„ì„ ë°©ì‹",
                    TEXT["run_page"]["mode_options"][lang],
                    index=0
                )
                # For both languages, "Single Question" is always first
                if lang == "í•œêµ­ì–´":
                    analysis_type_flag = analysis_type.startswith("ë‹¨ì¼")
                else:
                    analysis_type_flag = analysis_type.startswith("Single")

            selected_question_key = None
            selected_table = None
            tables = None
            question_texts = None
            question_keys = None


            if uploaded_file:
                try:
                    logger.info("Loading tables from uploaded file")
                    file_bytes = io.BytesIO(uploaded_file.read())
                    # Reset file pointer for future use
                    uploaded_file.seek(0)

                    tables, question_texts, question_keys = load_survey_tables(file_bytes)
                    logger.info(f"Successfully loaded {len(tables)} tables")
                except Exception as e:
                    logger.error(f"Error loading tables: {traceback.format_exc()}")
                    st.error(f"{TEXT['run_page']['upload_table_error'][lang]} {str(e)}")
                    st.stop()

################################## ë‹¨ì¼ index ë¶„ì„ ì‹¤í–‰ (analysis_type_flag: True) ##################################
                if analysis_type_flag and tables is not None:
                    # ì–´ë–¤ ì§ˆë¬¸ì— ëŒ€í•´ì„œ ì§„í–‰í• ì§€ ë¬¼ì–´ë³´ê¸°
                    st.subheader(TEXT["run_page"]["select_question_header"][lang])
                    st.info(TEXT["run_page"]["select_question_info"][lang])

                    normalized_question_texts = {normalize_key(k): v for k, v in question_texts.items()}
                    options = []
                    for key in question_keys:
                        norm_key = normalize_key(key)
                        if norm_key in normalized_question_texts:
                            label = normalized_question_texts[norm_key]
                            options.append(f"[{key}] {label}")
                        else:
                            st.warning(f"{TEXT['run_page']['missing_question_warning'][lang]} '{key}'")
                            logger.warning(f"Missing question text for key: {key}")

                    if not options:
                        st.error(TEXT["run_page"]["no_valid_questions"][lang])
                        logger.error("No valid question texts found")
                        st.stop()

                    # ì§ˆë¬¸ ì„ íƒì°½
                    selected_option = st.selectbox(TEXT["run_page"]["selectbox_label"][lang], options)
                    selected_index = options.index(selected_option)
                    selected_question_key = question_keys[selected_index].strip()
                    selected_key = normalize_key(selected_question_key)
                    normalized_tables = {normalize_key(k): v for k, v in tables.items()}
                    normalized_questions = {normalize_key(k): v for k, v in question_texts.items()}
                    
                    if selected_key not in normalized_tables:
                        st.error(f"âŒ ì„ íƒëœ ì§ˆë¬¸ í‚¤ '{selected_key}' ì— í•´ë‹¹í•˜ëŠ” í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                        st.stop()
                    
                    selected_table = normalized_tables[selected_key]
                    selected_question = normalized_questions[selected_key]

                    st.success(f"{TEXT['run_page']['selected_question'][lang]} {selected_question}")
                    st.dataframe(selected_table.head(), use_container_width=True)
################################## ì „ì²´ ì§ˆë¬¸ ë¶„ì„ ì‹¤í–‰ (analysis_type_flag: False) ##################################
                # question_keysì— ìˆëŠ” ëª¨ë“  indexë“¤ì— ëŒ€í•´ì„œ analysis ì§„í–‰ -> ì–´ë–»ê²Œ?
                elif not analysis_type_flag:
                    st.info(TEXT["run_page"]["batch_analysis_info"][lang])

            # flagì— ë”°ë¼ì„œ ë¶„ì„ ê³¼ì •ì„ ì‹¤í–‰ 

            # Per-question analysis plan UI for batch mode
            if not analysis_type_flag and tables is not None:
                st.subheader("ğŸ“Œ ì§ˆë¬¸ë³„ ë¶„ì„ ë°©ì‹ ì„¤ì •")
                st.markdown("ì•„ë˜ í‘œì—ì„œ ê° ì§ˆë¬¸ë³„ë¡œ í†µê³„ ë¶„ì„ ì‹¤í–‰ ì—¬ë¶€ì™€ ë¶„ì„ íƒ€ì…ì„ ì„¤ì •í•˜ì„¸ìš”.")
                st.info("ğŸ’¡ 'ì§‘ë‹¨ê°„ ì°¨ì´ ë¶„ì„ ì‹¤í–‰ ì—¬ë¶€'ë¥¼ ì²´í¬í•˜ë©´ í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì¶”ì²œ ë¶„ì„ ë°©ì‹ì´ ìë™ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.")

                user_analysis_plan = {}

                # ì´ˆê¸° ë°ì´í„° ì¤€ë¹„ (ì¶”ì²œ ë¶„ì„ ë°©ì‹ ë¯¸ë¦¬ ê³„ì‚°)
                recommendations = {}
                for key in question_keys:
                    try:
                        selected_table = tables.get(key)
                        from table_analysis_decision_test_type import rule_based_test_type_decision
                        llm_result = rule_based_test_type_decision(selected_table.columns, question_texts.get(key, ""))
                        
                        if llm_result == "ft_test":
                            recommendations[key] = "ì¶”ì²œ (F/T Test)"
                        elif llm_result == "chi_square":
                            recommendations[key] = "ì¶”ì²œ (Chi-Square)"
                        else:
                            recommendations[key] = "ì¶”ì²œ (ì„ì˜ ë¶„ì„)"
                    except Exception as e:
                        logger.error(f"í†µê³„ ê²€ì • ì¶”ì²œ ì˜¤ë¥˜ (key: {key}): {traceback.format_exc()}")
                        recommendations[key] = "ì¶”ì²œ (ì„ì˜ ë¶„ì„)"

                # ì´ˆê¸° ì„¸ì…˜ ìƒíƒœ ì„¤ì • (í•œ ë²ˆë§Œ)
                if "analysis_plan_state" not in st.session_state:
                    st.session_state["analysis_plan_state"] = {
                        key: {
                            "do_analyze": True,
                            "analysis_type": recommendations[key]
                        } for key in question_keys
                    }

                # í˜„ì¬ ìƒíƒœ ê¸°ë°˜ìœ¼ë¡œ í…Œì´ë¸” ë°ì´í„° êµ¬ì„±
                plan_table_data = []
                for key in question_keys:
                    current_state = st.session_state["analysis_plan_state"][key]
                    
                    # ì²´í¬ê°€ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´ ë¶„ì„ ë°©ì‹ì€ ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •
                    analysis_type_display = current_state["analysis_type"] if current_state["do_analyze"] else ""
                    
                    plan_table_data.append({
                        "ì§ˆë¬¸ Key": key,
                        "ì§ˆë¬¸ ë‚´ìš©": question_texts.get(key, ""),
                        "ì§‘ë‹¨ê°„ ì°¨ì´ ë¶„ì„ ì‹¤í–‰ ì—¬ë¶€": current_state["do_analyze"],
                        "í†µê³„ ë¶„ì„ ë°©ì‹": analysis_type_display
                    })

                import pandas as pd
                plan_df = pd.DataFrame(plan_table_data)

                # ë°ì´í„° ì—ë””í„°
                edited_df = st.data_editor(
                    plan_df,
                    column_config={
                        "ì§ˆë¬¸ Key": st.column_config.TextColumn("ì§ˆë¬¸ Key", width="small", disabled=True),
                        "ì§ˆë¬¸ ë‚´ìš©": st.column_config.TextColumn("ì§ˆë¬¸ ë‚´ìš©", width="large", disabled=True),
                        "ì§‘ë‹¨ê°„ ì°¨ì´ ë¶„ì„ ì‹¤í–‰ ì—¬ë¶€": st.column_config.CheckboxColumn("ì§‘ë‹¨ê°„ ì°¨ì´ ë¶„ì„ ì‹¤í–‰ ì—¬ë¶€", width="medium"),
                        "í†µê³„ ë¶„ì„ ë°©ì‹": st.column_config.SelectboxColumn(
                            "í†µê³„ ë¶„ì„ ë°©ì‹", 
                            options=["", "F/T Test", "Chi-Square", "ì„ì˜ ë¶„ì„", "ì¶”ì²œ (F/T Test)", "ì¶”ì²œ (Chi-Square)", "ì¶”ì²œ (ì„ì˜ ë¶„ì„)"],
                            required=False,
                            width="medium"
                        )
                    },
                    use_container_width=True,
                    hide_index=True,
                    key="plan_editor"   
                )

                # ìƒíƒœ ì—…ë°ì´íŠ¸ ë° ì¡°ê±´ë¶€ ë¶„ì„ ë°©ì‹ ì„¤ì •
                updated_state = {}
                for idx, row in edited_df.iterrows():
                    key = row["ì§ˆë¬¸ Key"]
                    do_analyze = row["ì§‘ë‹¨ê°„ ì°¨ì´ ë¶„ì„ ì‹¤í–‰ ì—¬ë¶€"]
                    analysis_type = row["í†µê³„ ë¶„ì„ ë°©ì‹"]
                    
                    if do_analyze:
                        # ì²´í¬ê°€ ë˜ì–´ ìˆëŠ”ë° ë¶„ì„ ë°©ì‹ì´ ë¹„ì–´ìˆìœ¼ë©´ ì¶”ì²œê°’ìœ¼ë¡œ ìë™ ì„¤ì •
                        if not analysis_type or analysis_type == "":
                            analysis_type = recommendations[key]
                        updated_state[key] = {
                            "do_analyze": True,
                            "analysis_type": analysis_type
                        }
                    else:
                        # ì²´í¬ê°€ í•´ì œë˜ë©´ ë¶„ì„ ë°©ì‹ë„ ë¹ˆ ë¬¸ìì—´ë¡œ ì´ˆê¸°í™”
                        updated_state[key] = {
                            "do_analyze": False,
                            "analysis_type": ""
                        }

                # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                st.session_state["analysis_plan_state"] = updated_state

                # ìµœì¢… ì‚¬ìš©ì ë¶„ì„ ê³„íš êµ¬ì„±
                user_analysis_plan = {
                    key: {
                        "do_analyze": state["do_analyze"],
                        "analysis_type": state["analysis_type"]
                    }
                    for key, state in updated_state.items()
                }

                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state["user_analysis_plan"] = user_analysis_plan

                # ìš”ì•½ ì •ë³´ í‘œì‹œ
                selected_count = sum(1 for state in updated_state.values() if state["do_analyze"])
                if selected_count > 0:
                    st.success(f"âœ… ì´ {selected_count}ê°œ ì§ˆë¬¸ì´ ë¶„ì„ ëŒ€ìƒìœ¼ë¡œ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    st.warning("âš ï¸ ë¶„ì„í•  ì§ˆë¬¸ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

            run = st.button(TEXT["run_page"]["run_button"][lang], use_container_width=True)

            if run:
                if uploaded_file is None:
                    st.error(TEXT["run_page"]["error_missing_file"][lang])
                    logger.error("Analysis started without uploaded file")
                    st.stop()
                if raw_data_file is None:
                    st.error(TEXT["run_page"]["error_missing_raw"][lang])
                    logger.error("Analysis started without raw data file")
                    st.stop()

                uploaded_file_content = uploaded_file.read()
                uploaded_file.seek(0)
                raw_data_content = raw_data_file.read()
                raw_data_file.seek(0)

                try:
                    logger.info("Reading raw data file")
                    raw_data_stream = io.BytesIO(raw_data_file.read())
                    # Reset file pointer for future use
                    raw_data_file.seek(0)
                except Exception as e:
                    logger.error(f"Raw data file processing error: {traceback.format_exc()}")
                    st.error(f"{TEXT['run_page']['raw_file_processing_error'][lang]} {str(e)}")
                    st.stop()

                try:
                    logger.info("Building table graph workflow")
                    workflow = build_table_graph()
                except Exception as e:
                    logger.error(f"Error building workflow: {traceback.format_exc()}")
                    st.error(f"{TEXT['run_page']['workflow_build_error'][lang]} {str(e)}")
                    st.stop()

                # ìµœì¢…ì ìœ¼ë¡œ LangGraphë¡œ ì „ë‹¬í•  state ì •ì˜
                init_state = {
                    "analysis_type": analysis_type_flag,
                    "uploaded_file": io.BytesIO(uploaded_file.read()),
                    "raw_data_file": raw_data_stream,
                    "lang": lang
                }

                if analysis_type_flag and selected_question_key is not None:
                    init_state["selected_key"] = selected_question_key

                # Single Question analysis
                if analysis_type_flag:
                    try:
                        logger.info("Invoking workflow")
                        if init_state.get("analysis_type", True):
                            with st.spinner(TEXT["run_page"]["analyzing_spinner"][lang]):
                                result = workflow.invoke(init_state)
                        else:
                            result = workflow.invoke(init_state)
                        logger.info("Workflow completed successfully")
                    except Exception as e:
                        logger.error(f"Workflow execution error: {traceback.format_exc()}")
                        st.error(f"{TEXT['run_page']['workflow_execute_error'][lang]} {str(e)}")
                        st.stop()

                    if init_state.get("analysis_type", True):
                        st.success(TEXT["run_page"]["analysis_done"][lang])

                        if "polishing_result" in result:
                            st.markdown(TEXT["run_page"]["final_result_title"][lang])
                            st.text_area("Polished Report", result["polishing_result"], height=300)
                        else:
                            st.warning(TEXT["run_page"]["no_result_warning"][lang])
                            logger.warning("No polishing_result in workflow output")
                # Batch analysis for all questions
                elif not analysis_type_flag:
                    all_results = {}
                    for key in question_keys:
                        plan = st.session_state.get("user_analysis_plan", {}).get(key, {})
                        if not plan.get("do_analyze", True):
                            continue  # skip if not selected

                        analysis_type_value = plan.get("analysis_type", "ìë™")
                        override_type = None
                        if analysis_type_value == "F/T Test":
                            override_type = "ft_test"
                        elif analysis_type_value == "Chi-Square":
                            override_type = "chi_square"

                        init_state_loop = {
                            "analysis_type": False,
                            "selected_key": key.strip(),
                            "uploaded_file": io.BytesIO(uploaded_file_content),
                            "raw_data_file": io.BytesIO(raw_data_content),
                            "lang": lang
                        }

                        # If override_type is None, determine LLM-based test type and inject to init_state_loop
                        if override_type is None:
                            # ìë™ ê²°ì • ì‹œ LLM ê¸°ë°˜ í†µê³„ ê²€ì • ë°©ë²• ì¶”ì²œ
                            selected_table = tables.get(key)
                            selected_key = normalize_key(key)

                            # test_type ì¶”ë¡ ì„ ìœ„í•œ state êµ¬ì„±
                            llm_state = {
                                "analysis_type": False,
                                "selected_key": selected_key,
                                "selected_table": selected_table,
                                "lang": lang,
                                "user_analysis_plan": user_analysis_plan
                            }

                            # LLM ê¸°ë°˜ test_type ê²°ì • í•¨ìˆ˜ í˜¸ì¶œ
                            try:
                                from table_analysis_decision_test_type import streamlit_test_type_decision_fn
                                
                                llm_result = streamlit_test_type_decision_fn(llm_state)
                                inferred_test_type = llm_result.get("test_type", None)
                                if inferred_test_type in ["ft_test", "chi_square"]:
                                    init_state_loop["test_type_override"] = inferred_test_type
                                    # Update user_analysis_plan to show display-friendly type
                                    test_type_label = "F/T Test" if inferred_test_type == "ft_test" else "Chi-Square"
                                    user_analysis_plan[key]["analysis_type"] = f"ì¶”ì²œ ({test_type_label})"
                                    st.session_state["user_analysis_plan"] = user_analysis_plan
                            except Exception as e:
                                logger.error(f"LLM test type decision error for key {key}: {traceback.format_exc()}")
                                # continue without test_type_override if error

                        else:
                            init_state_loop["test_type_override"] = override_type

                        try:
                            result = workflow.invoke(init_state_loop)
                            if "polishing_result" in result:
                                all_results[key] = result["polishing_result"]
                        except Exception as e:
                            logger.error(f"Workflow execution error for key {key}: {traceback.format_exc()}")
                            st.error(f"âŒ {key} ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                            continue

                    combined_result = "\n\n---\n\n".join(f"### [{k}]\n{v}" for k, v in all_results.items())
                    st.markdown(TEXT["run_page"]["final_result_title"][lang])
                    st.text_area("Combined Polished Report", combined_result, height=500)
                    return
    except Exception as e:
        logger.error(f"Unhandled exception: {traceback.format_exc()}")
        st.error(f"{TEXT['run_page']['unexpected_error'][lang]} {str(e)}")

if __name__ == "__main__":
    main()