import streamlit as st
import streamlit as st
import streamlit as st
import streamlit as st
import streamlit as st
import io
import os
import traceback
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

try:
    from dotenv import load_dotenv
    # Try importing your custom modules with error handling
    try:
        from streamlit_table_workflow_graph import build_table_graph
        from streamlit_table_parser import load_survey_tables
    except ImportError as e:
        st.error(f"âŒ Failed to import required modules: {e}")
        logger.error(f"Import error: {e}")
        st.stop()
except ImportError as e:
    st.error(f"âŒ Failed to import dotenv: {e}")
    logger.error(f"Dotenv import error: {e}")
    st.stop()

# ğŸ”‘ í™˜ê²½ ë³€ìˆ˜ ë¡œë”© (.env ë¡œì»¬ + st.secrets ë°°í¬ìš©)
try:
    load_dotenv()
    # Log API key status (without revealing the key)
    if "OPENAI_API_KEY" in os.environ:
        logger.info("OPENAI_API_KEY found in environment variables")
    
    if "OPENAI_API_KEY" in st.secrets:
        os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
        logger.info("OPENAI_API_KEY loaded from st.secrets")
    else:
        logger.warning("OPENAI_API_KEY not found in st.secrets")
        
    # Verify API key is set
    if "OPENAI_API_KEY" not in os.environ:
        st.warning("âš ï¸ OPENAI_API_KEY not set. Some features may not work.")
        logger.warning("OPENAI_API_KEY not set in environment")
except Exception as e:
    st.error(f"âŒ Error loading environment variables: {e}")
    logger.error(f"Environment error: {e}")

def normalize_key(key: str) -> str:
    return key.replace("-", "_").lower()

def main():
    try:
        st.set_page_config(page_title="Table Analysis Agent", layout="wide")

        page = st.sidebar.radio("í˜ì´ì§€ ì„ íƒ", ["ğŸ“– ì„œë¹„ìŠ¤ ì†Œê°œ", "ğŸ§ª ë¶„ì„ ì‹¤í–‰"])

        if page == "ğŸ“– ì„œë¹„ìŠ¤ ì†Œê°œ":
            st.title("ğŸ“– Table Analysis Agent ì†Œê°œ")
            st.markdown("""
ì´ ì„œë¹„ìŠ¤ëŠ” í†µê³„ ì¡°ì‚¬ ê²°ê³¼í‘œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìë™ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìš”ì•½í•´ì£¼ëŠ” ë©€í‹° ì—ì´ì „íŠ¸ ê¸°ë°˜ í”Œë«í¼ì…ë‹ˆë‹¤.

### âœ… ì‚¬ìš©ë˜ëŠ” ì£¼ìš” ì—ì´ì „íŠ¸ êµ¬ì„±:
- ğŸ“¥ **Table Parser**: ì—…ë¡œë“œí•œ ì—‘ì…€ íŒŒì¼ì—ì„œ ì„¤ë¬¸ ë¬¸í•­ê³¼ í†µê³„ í…Œì´ë¸”ì„ ìë™ìœ¼ë¡œ íŒŒì‹±
- âœï¸ **Hypothesis Generator**: í…Œì´ë¸”ì— ê¸°ë°˜í•œ ì´ˆê¸° ë¶„ì„ ê°€ì„¤ ìë™ ìƒì„±
- ğŸ§­ **Test Type Decision**: í†µê³„ì  ê²€ì • ë°©ì‹(F-test, T-test ë“±) ìë™ íŒë‹¨
- ğŸ“Š **F/T-Test Analyzer**: ìˆ˜ì¹˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í†µê³„ì  ìœ ì˜ì„± ê²€ì • ìˆ˜í–‰
- ğŸ“Œ **Anchor Extractor**: í…Œì´ë¸”ì—ì„œ ê°€ì¥ ë‘ë“œëŸ¬ì§„ ëŒ€ë¶„ë¥˜ í•­ëª©(anchor)ì„ ì¶”ì¶œ
- ğŸ“ **Table Analyzer**: ìˆ˜ì¹˜ì™€ anchorë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ˆê¸° ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
- ğŸ§  **Hallucination Checker**: ë³´ê³ ì„œì˜ ì˜¤ë¥˜ ì—¬ë¶€ íŒë‹¨ (LLM ê¸°ë°˜ ê²€ì¦)
- ğŸ” **Reviser**: ì˜ëª»ëœ ìš”ì•½ì„ í”¼ë“œë°± ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì •
- ğŸ’… **Polisher**: ìµœì¢… ìš”ì•½ì„ ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•˜ê²Œ ë‹¤ë“¬ëŠ” ì—­í• 

---

### ğŸ› ï¸ ì‚¬ìš© ë°©ë²• ì•ˆë‚´:
1. ì‚¬ì´ë“œë°”ì—ì„œ **ë¶„ì„ìš© í†µê³„í‘œ íŒŒì¼**ê³¼ **ì›ì‹œ ë°ì´í„° íŒŒì¼**ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.  
    - ë‘ íŒŒì¼ì€ ëª¨ë‘ **ì—‘ì…€(xlsx, xls)** í˜•ì‹ì´ë©° íŒŒì¼ëª…ì€ **ì˜ë¬¸** í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.
    - ë¶„ì„ìš© íŒŒì¼ì—ëŠ” ì„¤ë¬¸ ë¬¸í•­ë³„ í†µê³„ ìš”ì•½ í…Œì´ë¸”ì´ í¬í•¨ë˜ì–´ ìˆì–´ì•¼ í•˜ë©°, ê° ì‹œíŠ¸ ì´ë¦„ì€ ë¬¸í•­ í‚¤(ì˜ˆ: Q1, SQ3 ë“±)ë¡œ ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.  
    - ì›ì‹œ ë°ì´í„° íŒŒì¼ì—ëŠ” ìµœì†Œí•œ ë‹¤ìŒ ì‹œíŠ¸ê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤: `DATA`, `DEMO`
        - `DATA`: ê° ë¬¸í•­ë“¤(A1, A1_1, ...)ì— ëŒ€í•œ ì„¤ë¬¸ ì¡°ì‚¬ ê²°ê³¼ + í‘œë³¸ íŠ¹ì„±ë³„ë¡œ ì „ì²˜ë¦¬ê°€ ëœ ë³€ìˆ˜(DEMO1, DEMO2, ...)
        - `DEMO`: í‘œë³¸ íŠ¹ì„±ë³„ ë³€ìˆ˜ë“¤(DEMO1, DEMO2, ...)ì— ëŒ€í•œ ì„¤ëª…
    - í†µê³„í‘œëŠ” ë²”ì£¼í˜• ê°’ì— ëŒ€í•œ ë¹ˆë„ ë° ë¹„ìœ¨ì„ í¬í•¨í•˜ê³  ìˆì–´ì•¼ í•˜ë©°, ê²°ì¸¡ê°’ì€ ì œê±°ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
2. ë¶„ì„ ë°©ì‹ìœ¼ë¡œ **ë‹¨ì¼ ë¬¸í•­ ë¶„ì„** ë˜ëŠ” **ì „ì²´ ìë™ ë¶„ì„(batch)** ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
3. [ğŸš€ ë¶„ì„ ì‹œì‘] ë²„íŠ¼ì„ í´ë¦­í•˜ë©´, ìœ„ì˜ ì—ì´ì „íŠ¸ë“¤ì´ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.
4. ë¶„ì„ ê²°ê³¼ëŠ” ë‹¨ê³„ë³„ë¡œ ì¶œë ¥ë˜ë©°, ë§ˆì§€ë§‰ì—ëŠ” polishedëœ ìµœì¢… ë³´ê³ ì„œë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
5. í•„ìš” ì‹œ ìµœì¢… ë³´ê³ ì„œë¥¼ ë³µì‚¬í•˜ì—¬ í¸ì§‘í•˜ê±°ë‚˜ ì™¸ë¶€ ë³´ê³ ì„œë¡œ í™œìš©í•˜ì„¸ìš”.
""")
            st.markdown("### ğŸ§  ë©€í‹°ì—ì´ì „íŠ¸ ë¶„ì„ íë¦„ë„ (Mermaid Diagram)")
            mermaid_code = """
            <div class="mermaid">
            graph TD
                A[ğŸ“¥ table_parser] --> B[âœï¸ hypothesis_generate_node]
                B --> C[ğŸ§­ test_decision_node]
                C --> D[ğŸ“Š FT_anlysis_node]
                D --> E[ğŸ“Œ get_anchor_node]
                E --> F[ğŸ“ table_analyzer]
                F --> G[ğŸ§  hallucination_check_node]

                G -- accept --> H[ğŸ’… sentence_polish_node]
                G -- reject < 4 --> I[ğŸ” revise_table_analysis]
                I --> G
                G -- reject â‰¥ 4 --> H

                H --> Z([âœ… END])
            </div>
            <script type="module">
            import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
            mermaid.initialize({ startOnLoad: true });
            </script>
            """
            st.components.v1.html(mermaid_code, height=800)
            return

        if page == "ğŸ§ª ë¶„ì„ ì‹¤í–‰":
            st.title("ğŸ“Š Table Statistical Analysis Multi-Agent")

            st.info("âš ï¸ **ì—…ë¡œë“œí•  íŒŒì¼ ì´ë¦„ì€ ë°˜ë“œì‹œ ì˜ë¬¸ ë˜ëŠ” ìˆ«ìë¡œ êµ¬ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.**")
            st.markdown("í•œê¸€, ê³µë°±, íŠ¹ìˆ˜ë¬¸ìê°€ í¬í•¨ëœ ê²½ìš° ì—…ë¡œë“œê°€ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆ: `data_2024.xlsx` âœ…")

            st.markdown("""
            - Excel í†µê³„í‘œ ê¸°ë°˜ ë¶„ì„ ìë™í™”
            - Upload File â†’ Parsing â†’ Hypothesis â†’ Numeric Analysis â†’ Table Analysis â†’ Hallucination Check â†’ Revision â†’ Polishing
            """)

            # âœ… ì‚¬ì´ë“œë°”: ì—…ë¡œë“œ
            with st.sidebar:
                st.header("1ï¸âƒ£ ë¶„ì„ìš© Excel íŒŒì¼ ì—…ë¡œë“œ (í†µê³„í‘œ)")
                uploaded_file = st.file_uploader("ğŸ“¥ ë¶„ì„ìš© Excel íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type=None)

                st.header("2ï¸âƒ£ ì›ì‹œ ë°ì´í„° Excel íŒŒì¼ ì—…ë¡œë“œ (Raw DATA, ë³€ìˆ˜, ì½”ë”©ê°€ì´ë“œ, ë¬¸í•­ í¬í•¨)")
                raw_data_file = st.file_uploader("ğŸ“¥ ì›ì‹œ ë°ì´í„° Excel íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type=None, key="raw_data")

                st.header("3ï¸âƒ£ ë¶„ì„ ë°©ì‹ ì„ íƒ")
                analysis_type = st.radio(
                    "ë¶„ì„ ë°©ì‹",
                    ["ë‹¨ì¼ ì§ˆë¬¸ ì„ íƒ - ì§ì ‘ ì„ íƒ", "ì „ì²´ ì§ˆë¬¸ batch - ì „ì²´ ìë™ ë¶„ì„"],
                    index=0
                )
                analysis_type_flag = analysis_type.startswith("ë‹¨ì¼")

            selected_question_key = None
            selected_table = None
            tables = None
            question_texts = None
            question_keys = None

            if uploaded_file:
                try:
                    logger.info("Loading tables from uploaded file")
                    file_bytes = io.BytesIO(uploaded_file.read())
                    # Reset file pointer for future use
                    uploaded_file.seek(0)
                    
                    tables, question_texts, question_keys = load_survey_tables(file_bytes)
                    logger.info(f"Successfully loaded {len(tables)} tables")
                except Exception as e:
                    logger.error(f"Error loading tables: {traceback.format_exc()}")
                    st.error(f"âŒ ì—…ë¡œë“œëœ í†µê³„í‘œ íŒŒì¼ì—ì„œ í…Œì´ë¸”ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    st.stop()

                if analysis_type_flag and tables is not None:
                    st.subheader("4ï¸âƒ£ ë¶„ì„í•  ì§ˆë¬¸ ì„ íƒ")
                    st.info("ğŸ“‹ ì—…ë¡œë“œí•œ ë¶„ì„ìš© Excel íŒŒì¼ì˜ ì§ˆë¬¸ ëª©ë¡ì…ë‹ˆë‹¤. ë¶„ì„í•  ì§ˆë¬¸ì„ ì„ íƒí•˜ì„¸ìš”.")

                    normalized_question_texts = {normalize_key(k): v for k, v in question_texts.items()}
                    options = []
                    for key in question_keys:
                        norm_key = normalize_key(key)
                        if norm_key in normalized_question_texts:
                            label = normalized_question_texts[norm_key]
                            options.append(f"[{key}] {label}")
                        else:
                            st.warning(f"âš ï¸ ì§ˆë¬¸ í…ìŠ¤íŠ¸ ëˆ„ë½: '{key}'")
                            logger.warning(f"Missing question text for key: {key}")

                    if not options:
                        st.error("âŒ ìœ íš¨í•œ ì§ˆë¬¸ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        logger.error("No valid question texts found")
                        st.stop()

                    selected_option = st.selectbox("ì§ˆë¬¸ ëª©ë¡", options)
                    selected_index = options.index(selected_option)
                    selected_question_key = question_keys[selected_index]
                    selected_table = tables[selected_question_key]

                    st.success(f"âœ… ì„ íƒëœ ì§ˆë¬¸: {question_texts.get(selected_question_key, selected_question_key)}")
                    st.dataframe(selected_table.head(), use_container_width=True)
                elif not analysis_type_flag:
                    st.info("ğŸ“Œ ì „ì²´ batch ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ê° ì§ˆë¬¸ì€ ìë™ ë¶„ì„ë©ë‹ˆë‹¤.")

            run = st.button("ğŸš€ ë¶„ì„ ì‹œì‘", use_container_width=True)

            if run:
                if uploaded_file is None:
                    st.error("â— ë¶„ì„ìš© Excel íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”.")
                    logger.error("Analysis started without uploaded file")
                    st.stop()
                if raw_data_file is None:
                    st.error("â— ì›ì‹œ ë°ì´í„° Excel íŒŒì¼ë„ ë°˜ë“œì‹œ ì—…ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.")
                    logger.error("Analysis started without raw data file")
                    st.stop()

                try:
                    logger.info("Reading raw data file")
                    raw_data_stream = io.BytesIO(raw_data_file.read())
                    # Reset file pointer for future use
                    raw_data_file.seek(0)
                except Exception as e:
                    logger.error(f"Raw data file processing error: {traceback.format_exc()}")
                    st.error(f"âŒ ì›ì‹œ ë°ì´í„° íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                    st.stop()

                try:
                    logger.info("Building table graph workflow")
                    workflow = build_table_graph()
                except Exception as e:
                    logger.error(f"Error building workflow: {traceback.format_exc()}")
                    st.error(f"âŒ ì›Œí¬í”Œë¡œìš° ë¹Œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    st.stop()

                init_state = {
                    "analysis_type": analysis_type_flag,
                    "uploaded_file": io.BytesIO(uploaded_file.read()),
                    "raw_data_file": raw_data_stream,
                }

                if analysis_type_flag and selected_question_key is not None:
                    init_state["selected_key"] = selected_question_key

                try:
                    logger.info("Invoking workflow")
                    with st.spinner("ë¶„ì„ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”"):
                        result = workflow.invoke(init_state)
                    logger.info("Workflow completed successfully")
                except Exception as e:
                    logger.error(f"Workflow execution error: {traceback.format_exc()}")
                    st.error(f"âŒ ë¶„ì„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    st.stop()

                st.success("ğŸ‰ ë¶„ì„ ì™„ë£Œ!")

                if "polishing_result" in result:
                    st.markdown("### ğŸ” ìµœì¢… ìš”ì•½ ê²°ê³¼")
                    st.text_area("Polished Report", result["polishing_result"], height=300)
                else:
                    st.warning("âš ï¸ ìµœì¢… ê²°ê³¼ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    logger.warning("No polishing_result in workflow output")
    except Exception as e:
        logger.error(f"Unhandled exception: {traceback.format_exc()}")
        st.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

if __name__ == "__main__":
    main()