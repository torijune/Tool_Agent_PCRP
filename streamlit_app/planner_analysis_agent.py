from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI
import os
from dotenv import load_dotenv

load_dotenv()

llm = ChatOpenAI(temperature=0.3, model="gpt-4o-mini", openai_api_key=os.getenv("OPENAI_API_KEY"))

ANALYSIS_SUGGESTION_PROMPT = {
    "í•œêµ­ì–´": """
ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ë° ì„¤ë¬¸ì¡°ì‚¬ í•´ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê° ì„¤ë¬¸ ë¬¸í•­ì— ê°€ì¥ ì í•©í•œ í†µê³„ ë¶„ì„ ë°©ë²•ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”:
- ê° ë¬¸í•­ì´ ì¸¡ì •í•˜ëŠ” ê°œë…(íƒœë„, í–‰ë™, ì¸ì‹ ë“±)ì— ë”°ë¼ ì ì ˆí•œ ë¶„ì„ ê¸°ë²•ì„ ì œì‹œ
- ì‘ë‹µ ìœ í˜•(ê°ê´€ì‹, ë¦¬ì»¤íŠ¸ ì²™ë„, ì£¼ê´€ì‹ ë“±)ì„ ê³ ë ¤í•˜ì—¬ ì í•©í•œ í†µê³„ ë¶„ì„ ë˜ëŠ” ê²€ì • ë°©ë²•(ë¹ˆë„ë¶„ì„, êµì°¨ë¶„ì„, t-test, ANOVA, ìƒê´€ë¶„ì„ ë“±)ì„ ì„¤ëª…
- ë¬¸í•­ë³„ ì¶”ì²œ ì´ìœ ì™€ í•¨ê»˜ ë¶„ì„ ì‹œ ìœ ì˜í•´ì•¼ í•  ì ë„ ê°„ë‹¨íˆ ê¸°ìˆ 
- ì „ì²´ ì¡°ì‚¬ ëª©ì ê³¼ì˜ ì—°ê´€ì„±ë„ ë°˜ì˜

ğŸ“Œ ì¡°ì‚¬ ì£¼ì œ: {topic}
ğŸ“Œ ì¡°ì‚¬ ëª©ì : {generated_objective}
ğŸ“Œ ë¬¸í•­ ëª©ë¡:
{questions}

---

ğŸ“Š ë¬¸í•­ë³„ ë¶„ì„ ì œì•ˆ:
""",

    "English": """
You are a data analyst and survey interpretation expert.

Based on the following information, recommend the most appropriate statistical analysis or test method for each survey question:
- Consider the conceptual focus of each question (e.g., attitude, behavior, awareness)
- Suggest analysis methods (e.g., frequency, cross-tabulation, t-test, ANOVA, correlation) that match the question type (multiple choice, Likert scale, open-ended)
- For each question, explain why the method is appropriate and what the user should be cautious about
- Align the analysis plan with the overall research objective

ğŸ“Œ Topic: {topic}
ğŸ“Œ Objective: {generated_objective}
ğŸ“Œ Question List:
{questions}

---

ğŸ“Š Suggested Statistical Methods for Each Question:
"""
}

# âœ… LangGraph-compatible Node Function
def planner_analysis_agent_fn(state):
    topic = state["topic"]
    generated_objective = state["generated_objective"]
    structure = state["structure"]
    questions = state["questions"]
    lang = state.get("lang", "í•œêµ­ì–´")

    prompt = ANALYSIS_SUGGESTION_PROMPT[lang].format(
        topic=topic,
        generated_objective=generated_objective,
        structure=structure,
        questions=questions
    )
    response = llm.invoke(prompt)
    import streamlit as st
    st.markdown("### ğŸ“Š ë¶„ì„ ì œì•ˆ ë° ê³ ë ¤ì‚¬í•­" if lang == "í•œêµ­ì–´" else "### ğŸ“Š Suggested Analysis and Considerations")
    st.code(response.content.strip(), language="markdown")
    return {
        **state,
        "analysis": response.content.strip()
    }

analysis_agent_node = RunnableLambda(planner_analysis_agent_fn)