import pandas as pd
import re
from collections import defaultdict

import streamlit as st
from langchain_core.runnables import RunnableLambda

def load_survey_tables(file_obj, sheet_name: str = "í†µê³„í‘œ"):
    df = pd.read_excel(file_obj, sheet_name=sheet_name, header=None)
    pattern = r"^[A-Z]+\d*[-.]?\d*\."
    question_indices = df[df[0].astype(str).str.match(pattern)].index.tolist()

    tables, question_texts, question_keys = {}, {}, []
    key_counts = defaultdict(int)

    for i, start in enumerate(question_indices):
        end = question_indices[i + 1] if i + 1 < len(question_indices) else len(df)
        title = str(df.iloc[start, 0]).strip()
        match = re.match(pattern, title)
        if not match:
            continue
        base_key = match.group().rstrip(".")
        key_counts[base_key] += 1
        suffix = f"_{key_counts[base_key]}" if key_counts[base_key] > 1 else ""
        final_key = base_key + suffix

        question_texts[final_key] = title + "(ì „ì²´ ë‹¨ìœ„ : %)"
        question_keys.append(final_key)

        table = df.iloc[start + 1:end].reset_index(drop=True)
        if len(table) >= 2:
            new_columns = table.iloc[0].fillna('').astype(str) + " " + table.iloc[1].fillna('').astype(str)
            new_columns.iloc[0] = "ëŒ€ë¶„ë¥˜"
            if len(new_columns) > 1:
                new_columns.iloc[1] = "ì†Œë¶„ë¥˜"
            table = table.drop([0, 1]).reset_index(drop=True)
            table.columns = new_columns
            table["ëŒ€ë¶„ë¥˜"] = table["ëŒ€ë¶„ë¥˜"].ffill()
            table = table.dropna(axis=1, how='all').dropna(axis=0, how='all')
            table = table.drop(index=0).reset_index(drop=True)
            if len(table) > 2:
                table = table.iloc[:-2].reset_index(drop=True)

            for col in table.columns:
                try:
                    numeric_col = pd.to_numeric(table[col], errors='coerce')
                    if numeric_col.notna().any():
                        table[col] = numeric_col.round(1)
                except Exception:
                    continue

            tables[final_key] = table

    return tables, question_texts, question_keys

def linearize_row_wise(df):
    return " | ".join(
        ["; ".join([f"{col}: {val}" for col, val in row.items()]) for _, row in df.iterrows()]
    )

def table_parser_node_fn(state):
    analysis_type = state.get("analysis_type", True)
    uploaded_file = state.get("uploaded_file", None)
    selected_key = state.get("selected_key", None)   # âœ… app.pyì—ì„œ ë„˜ê¸´ selected_key ì‚¬ìš©

    if uploaded_file is None:
        st.warning("âš ï¸ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”.")
        st.stop()

    tables, question_texts, question_keys = load_survey_tables(uploaded_file)

    # âœ… selected_keyê°€ stateì— ìˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if selected_key is not None:
        selected_table = tables[selected_key]
        selected_question = question_texts[selected_key]

    # âœ… ë‹¨ì¼ ì„ íƒ ëª¨ë“œ (streamlitì—ì„œ ì„ íƒ â†’ ë¹„ê¶Œì¥, í˜¸í™˜ìš©)
    elif analysis_type:
        options = [f"[{key}] {question_texts[key]}" for key in question_keys]
        selected_option = st.selectbox("ğŸ“ ì§ˆë¬¸ ëª©ë¡", options)
        selected_index = options.index(selected_option)
        selected_key = question_keys[selected_index]
        selected_table = tables[selected_key]
        selected_question = question_texts[selected_key]

    # âœ… batch ëª¨ë“œ â†’ ì „ì²´ íŒŒì¼ì—ì„œ ì²« ë²ˆì§¸ í…Œì´ë¸”ë¡œ ì„¤ì •
    else:
        selected_key = question_keys[0]
        selected_table = tables[selected_key]
        selected_question = question_texts[selected_key]

    linearized_table = linearize_row_wise(selected_table)

    return {
        **state,
        "tables": tables,
        "question_texts": question_texts,
        "selected_table": selected_table,
        "table": tables,
        "selected_question": selected_question,
        "question_keys": question_keys,
        "selected_key": selected_key,
        "linearized_table": linearized_table,
    }

streamlit_table_parser_node = RunnableLambda(table_parser_node_fn)