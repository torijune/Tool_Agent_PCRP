import os
import openai
import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableLambda

# âœ… í™˜ê²½ ì„¤ì •
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)

# âœ… ìˆ˜ì • í”„ë¡¬í”„íŠ¸
REVISION_PROMPT = """
ë‹¹ì‹ ì€ í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸êµ¬ì§‘ë‹¨ ê°„ íŒ¨í„´ê³¼ ê²½í–¥ì„±ì„ ê°ê´€ì ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” í…Œì´ë¸” ë¶„ì„ ê²°ê³¼ì— ëŒ€í•´ ì¼ë¶€ ì˜ëª»ëœ í•´ì„ì´ í¬í•¨ëœ ìš”ì•½ì…ë‹ˆë‹¤. í”¼ë“œë°±ê³¼ ì‚¬ì „ì— ìƒì„±ëœ ê°€ì„¤ì„ ì°¸ê³ í•˜ì—¬ ì˜ëª»ëœ ë‚´ìš©ì„ ì œê±°í•˜ê³ , ì›ë³¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì¹˜ ê¸°ë°˜ì˜ ê°ê´€ì  ë¶„ì„ì„ ë‹¤ì‹œ ì‘ì„±í•  ê²ƒ.

ğŸ“Š í‘œ ë°ì´í„° (ì„ í˜•í™”ëœ í˜•íƒœ):
{linearized_table}

ğŸ“ˆ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ (F/T-test ê²°ê³¼ ìš”ì•½):
{ft_test_summary}

ğŸ“ Rejectëœ ë³´ê³ ì„œ (ìˆ˜ì •í•´ì•¼í•  ë³´ê³ ì„œ):
{table_analysis}

â— í”¼ë“œë°± (ìˆ˜ì •ì´ í•„ìš”í•œ ì´ìœ  ë˜ëŠ” ì˜ëª»ëœ ë¶€ë¶„):
{feedback}

---

Let's think step by step

ğŸ¯ ìˆ˜ì • ë° ì¬ì‘ì„± ì§€ì¹¨:

1. ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ëŒ€ë¶„ë¥˜ í•­ëª©(ë³„í‘œê°€ ìˆëŠ” í•­ëª©)ì€ ë°˜ë“œì‹œ ìš”ì•½ì— ì–¸ê¸‰í•  ê²ƒ
2. ì™¸ë¶€ ë°°ê²½ì§€ì‹, ì£¼ê´€ì  í•´ì„ ì—†ì´ ì˜¤ì§ ìˆ˜ì¹˜ ê¸°ë°˜ ì‚¬ì‹¤ë§Œ ì‘ì„±í•  ê²ƒ
3. í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•Šì€ í•­ëª©(p-value â‰¥ 0.05, ë³„í‘œ ì—†ìŒ)ì€ ì ˆëŒ€ ìš”ì•½ì— í¬í•¨í•˜ì§€ ë§ ê²ƒ
4. ìˆ«ì ê¸°ë°˜ì˜ ê²½í–¥ì„ ì¤‘ì‹¬ìœ¼ë¡œ "ìƒëŒ€ì ìœ¼ë¡œ ë” ë†’ì€ ê²½í–¥ ë³´ì˜€ìŒ", "ë‚®ì€ ê°’ì„ ë‚˜íƒ€ëƒˆìŒ" ë“± ìŒìŠ´ì²´ë¡œ ì‘ì„±í•  ê²ƒ
5. ë¬¸ì¥ì€ í‰ì„œë¬¸ì´ ì•„ë‹Œ, ë³´ê³ ì„œ ìŒìŠ´ì²´ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±í•  ê²ƒ (ì˜ˆ: ~í–ˆìŒ, ~ë¡œ ë‚˜íƒ€ë‚¬ìŒ)
6. ë„ˆë¬´ ë‹¨ì ˆì  (~í–ˆìŒ. ~í–ˆìŒ.) í‘œí˜„ì€ í”¼í•˜ê³ , ì—°ê²°ì–´ë¥¼ í™œìš©í•´ ìì—°ìŠ¤ëŸ½ê²Œ ì„œìˆ í•  ê²ƒ
7. ì •í™•í•œ ìˆ˜ì¹˜ê°’ì€ ì“°ì§€ ë§ê³ , ìˆ˜ì¹˜ ì°¨ì´ì— ê¸°ë°˜í•œ ê²½í–¥ë§Œ ì„œìˆ í•  ê²ƒ
8. ì‚¬ì†Œí•œ ì°¨ì´ëŠ” ë¬´ì‹œí•˜ê³ , ìœ ì˜í•œ í•­ëª©ë§Œ ì¤‘ì‹¬ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•  ê²ƒ
9. ë™ì¼ ì˜ë¯¸ì˜ ê·¸ë£¹ì´ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•  ê²ƒ
"""

# âœ… LangGraph ë…¸ë“œ í•¨ìˆ˜
def streamlit_revise_table_analysis_fn(state):
    st.info("âœ… [Revision Agent] Start table analysis revision")

    # ğŸ“Œ table_analysisëŠ” revisedê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ìš°ì„ , ì—†ìœ¼ë©´ ì´ˆì•ˆì„ fallback
    table_analysis = state.get("revised_analysis") or state.get("table_analysis", "")

    prompt = REVISION_PROMPT.format(
        linearized_table=state["linearized_table"],
        ft_test_summary=str(state["ft_test_summary"]),
        table_analysis=table_analysis,
        feedback=state["feedback"]
    )

    with st.spinner("LLM Revision Agentê°€ ìˆ˜ì • ë³´ê³ ì„œë¥¼ ì‘ì„± ì¤‘..."):
        response = llm.invoke(prompt)

    revised_analysis = response.content.strip()

    st.success("ğŸ‰ ìˆ˜ì •ëœ ìµœì¢… ë³´ê³ ì„œ:")
    st.text(revised_analysis)

    return {
        **state,
        "revised_analysis": revised_analysis
    }

# âœ… LangGraph ë…¸ë“œ ë“±ë¡
streamlit_revise_table_analysis_node = RunnableLambda(streamlit_revise_table_analysis_fn)