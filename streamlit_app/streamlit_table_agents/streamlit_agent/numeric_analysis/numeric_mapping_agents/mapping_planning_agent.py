# mapping_planning_agent.py
# [Step 2ï¸âƒ£] mapping ê³„íš ìˆ˜ë¦½: ê° ë³€ìˆ˜ì— ëŒ€í•´ ì–´ë–¤ ê°’ì´ ì–´ë–¤ labelë¡œ mapping ë˜ì–´ì•¼ í• ì§€ ê³„íšì„ ì„¸ìš°ì„¸ìš”.  

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableLambda

load_dotenv()
llm = ChatOpenAI(temperature=0.2, model="gpt-4o")

# ğŸ¯ Step 2: mapping ê³„íš ìˆ˜ë¦½ í”„ë¡¬í”„íŠ¸
MAPPING_PLANNING_PROMPT = """
ë‹¹ì‹ ì€ í†µê³„ ì¡°ì‚¬ raw dataë¥¼ ë¶„ì„í•˜ê³  mapping ê³„íšì„ ìˆ˜ë¦½í•˜ëŠ” AI Assistantì…ë‹ˆë‹¤.

ì•„ë˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê° ë³€ìˆ˜ì— ëŒ€í•´ ì–´ë–¤ ê°’(code)ì´ ì–´ë–¤ labelë¡œ mapping ë˜ì–´ì•¼ í• ì§€ mapping table í˜•íƒœë¡œ ì •ë¦¬í•˜ì„¸ìš”.

[ëŒ€ë¶„ë¥˜ ê°’ ëª©ë¡]
{major_str}

[ì†Œë¶„ë¥˜ ê°’ ëª©ë¡]
{minor_str}

[Raw Data Code Guide (ì¼ë¶€)]
{code_guide_str}

[Raw Data ë³€ìˆ˜ ì„¤ëª…]
{raw_variables}

[ë³€ìˆ˜ ì˜ë¯¸ ì¶”ë¡  ê²°ê³¼]
{semantics_result}

ì¶œë ¥ ì˜ˆì‹œ:
ë³€ìˆ˜ëª…:
    - code: label
    - code: label
...
"""

def mapping_planning_fn(state: dict) -> dict:
    major_str = state.get("major_str", "")
    minor_str = state.get("minor_str", "")
    code_guide_str = state.get("code_guide_str", "")
    raw_variables = state.get("raw_variables", "")
    semantics_result = state.get("semantics_result", "")

    prompt = MAPPING_PLANNING_PROMPT.format(
        major_str=major_str,
        minor_str=minor_str,
        code_guide_str=code_guide_str,
        raw_variables=raw_variables,
        semantics_result=semantics_result
    )

    response = llm.invoke(prompt)
    mapping_plan_result = response.content.strip()

    print("ğŸ“ Mapping ê³„íš ìˆ˜ë¦½ ì™„ë£Œ.")
    return {**state, "mapping_plan_result": mapping_plan_result}

# âœ… LangGraph Node ì •ì˜
mapping_planning_node = RunnableLambda(mapping_planning_fn)