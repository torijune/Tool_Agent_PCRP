import os
import openai
import streamlit as st

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableLambda

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° API í‚¤ ì„¤ì •
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# âœ… LLM ì„¤ì •
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.5, openai_api_key=api_key)

HALLUCINATION_CHECK_PROMPT = """
ë‹¹ì‹ ì€ í†µê³„ í•´ì„ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ì˜ í…Œì´ë¸” ë°ì´í„°ì™€ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼(F/T-test ê¸°ë°˜), ê·¸ë¦¬ê³  í•´ë‹¹ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ëœ ìš”ì•½ ë³´ê³ ì„œê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤.

ğŸ“ ì„¤ë¬¸ ë¬¸í•­:
{selected_question}

ğŸ“Š ì„ í˜•í™”ëœ í…Œì´ë¸”:
{linearized_table}

ğŸ“ˆ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ (F/T-test ê²°ê³¼ ìš”ì•½):
{ft_test_summary}

ğŸ§¾ ìƒì„±ëœ ìš”ì•½:
{table_analysis}

---

ì´ ìš”ì•½ì´ ìœ„ì˜ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ë¥¼ **ì •í™•í•˜ê³  ì¼ê´€ì„± ìˆê²Œ** ë°˜ì˜í•˜ê³  ìˆëŠ”ì§€ í‰ê°€í•´ì£¼ì„¸ìš”.

âš ï¸ ì£¼ì˜ ì‚¬í•­ (ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¼ë„ ìœ„ë°˜ë˜ë©´ reject):
1. F/T-testì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ í™•ì¸ëœ ëŒ€ë¶„ë¥˜ê°€ ìš”ì•½ì— ì–¸ê¸‰ë˜ì§€ ì•Šì€ ê²½ìš°
2. ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ í™•ì¸ëœ ëŒ€ë¶„ë¥˜ì—ì„œì˜ ì£¼ìš” ê²½í–¥ì´ë‚˜ ìˆ˜ì¹˜ ê²°ê³¼ê°€ ì™œê³¡ë˜ì–´ í•´ì„ëœ ê²½ìš° (e.g. ë” ë†’ì§€ ì•Šì€ë° ë” ë†’ë‹¤ê³  ì˜ëª» ëœ ì£¼ì¥ì„ í•˜ëŠ” ê²½ìš°)
3. í‘œí˜„ ì°¨ì´, ë¬¸ì¥ ìˆœì„œ, ì–´ì¡°ëŠ” í—ˆìš©ë˜ì§€ë§Œ ë³¸ì§ˆì  ë‚´ìš© ì™œê³¡ì€ reject

ğŸ¯ í‰ê°€ ë°©ì‹:
- ìš”ì•½ì´ ì „ì²´ì ìœ¼ë¡œ ì‹ ë¢°í•  ë§Œí•˜ê³  í†µê³„ ê²°ê³¼ë¥¼ ì˜ ë°˜ì˜í•˜ë©´ "accept"
- ìœ„ í•­ëª© ìœ„ë°˜ ì‹œ "reject: [ì´ìœ ]" í˜•ì‹ìœ¼ë¡œ ì¶œë ¥

â€» íŠ¹íˆ F/T-test ê²°ê³¼ëŠ” í•µì‹¬ ê¸°ì¤€ì…ë‹ˆë‹¤. ìœ ì˜ë¯¸í•œ ê²°ê³¼ê°€ ìš”ì•½ì—ì„œ ë¹ ì§„ ê²½ìš° ë°˜ë“œì‹œ reject í•˜ì„¸ìš”.
"""

# âœ… LangGraph-compatible hallucination ì²´í¬ ë…¸ë“œ
def streamlit_hallucination_check_node_fn(state):
    st.info("âœ… [Hallucination Check Agent] Start hallucination evaluation")

    hallucination_reject_num = state.get("hallucination_reject_num", 0)

    # ğŸ” ìˆ˜ì • ì—¬ë¶€ì— ë”°ë¼ ë¶„ì„ ê²°ê³¼ ì„ íƒ
    table_analysis = (
        state["table_analysis"]
        if hallucination_reject_num == 0
        else state["revised_analysis"]
    )

    # âœ… í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = HALLUCINATION_CHECK_PROMPT.format(
        selected_question=state["selected_question"],
        linearized_table=state["linearized_table"],
        ft_test_summary=str(state["ft_test_summary"]),
        table_analysis=table_analysis
    )

    # âœ… LLM í˜¸ì¶œ
    with st.spinner("Hallucination í‰ê°€ ì¤‘..."):
        response = llm.invoke(prompt)

    result = response.content.strip()

    # âœ… ê²°ê³¼ í•´ì„ ë° ìƒíƒœ ì—…ë°ì´íŠ¸
    if result.lower().startswith("reject"):
        decision = "reject"
        feedback = result[len("reject"):].strip(": ").strip()
        hallucination_reject_num += 1
        st.warning(f"âŒ Hallucination Check ê²°ê³¼: {decision}")
        st.info(f"ğŸ’¡ LLM Feedback: {feedback}")
    else:
        decision = "accept"
        feedback = ""
        st.success(f"âœ… Hallucination Check ê²°ê³¼: {decision}")

    return {
        **state,
        "hallucination_check": decision,
        "feedback": feedback,
        "hallucination_reject_num": hallucination_reject_num
    }

streamlit_hallucination_check_node = RunnableLambda(streamlit_hallucination_check_node_fn)