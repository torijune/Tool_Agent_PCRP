import os
import openai
import streamlit as st

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableLambda

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° API í‚¤ ì„¤ì •
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# âœ… LLM ì„¤ì •
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.5)

# âœ… í”„ë¡¬í”„íŠ¸ ì •ì˜ (ft_test_summary ì‚¬ìš©)
HALLUCINATION_CHECK_PROMPT = """
ë‹¹ì‹ ì€ í†µê³„ í•´ì„ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ì˜ í…Œì´ë¸” ë°ì´í„°ì™€ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼, ê·¸ë¦¬ê³  í•´ë‹¹ í…Œì´ë¸”ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ëœ ìš”ì•½ ê²°ê³¼ê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤.

ğŸ“ ì„¤ë¬¸ ë¬¸í•­:
{selected_question}

ğŸ“Š ì„ í˜•í™”ëœ í…Œì´ë¸”:
{linearized_table}

ğŸ“ˆ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ (F/T-test ê²°ê³¼ ìš”ì•½):
{ft_test_summary}

ğŸ§¾ ìƒì„±ëœ ìš”ì•½:
{table_analysis}

ì´ ìš”ì•½ì´ ìœ„ì˜ í‘œì™€ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ë¥¼ **í¬ê²Œ ë²—ì–´ë‚˜ì§€ ì•Šê³  ì „ë°˜ì ìœ¼ë¡œ ì¼ê´€ì„± ìˆê²Œ** ë°˜ì˜í•˜ê³  ìˆëŠ”ì§€ í‰ê°€í•´ì£¼ì„¸ìš”.

âš ï¸ ì£¼ì˜:
- ì•½ê°„ì˜ í‘œí˜„ ì°¨ì´, ì–´ìˆœ ë³€í™”, ê²½ë¯¸í•œ í•´ì„ì  í‘œí˜„ì€ í—ˆìš©ë©ë‹ˆë‹¤.
- ë‹¤ë§Œ **ì¤‘ìš” ìˆ˜ì¹˜, ì£¼ìš” ê²½í–¥, ê·¸ë£¹ ê°„ ìˆœìœ„** ë“± í•µì‹¬ì ì¸ ì‚¬ì‹¤ ì™œê³¡ì´ ìˆìœ¼ë©´ reject í•˜ì„¸ìš”.

ğŸ¯ í‰ê°€ ë°©ì‹:
- ìš”ì•½ì´ ì „ì²´ì ìœ¼ë¡œ ì‹ ë¢°í•  ë§Œí•˜ê³  ì‚¬ì‹¤ ê¸°ë°˜ì´ë©´ "accept"ë¼ê³ ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
- ìš”ì•½ì—ì„œ **ëª…í™•í•œ ì‚¬ì‹¤ ì˜¤ë¥˜, ìˆ˜ì¹˜ ì™œê³¡, ì˜ëª»ëœ ê²°ë¡ **ì´ ìˆìœ¼ë©´ "reject: [ì´ìœ ]" í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
"""

# âœ… LangGraph-compatible hallucination ì²´í¬ ë…¸ë“œ
def streamlit_hallucination_check_node_fn(state):
    st.info("âœ… [Hallucination Check Agent] Start hallucination evaluation")

    hallucination_reject_num = state.get("hallucination_reject_num", 0)

    # ğŸ” ìˆ˜ì • ì—¬ë¶€ì— ë”°ë¼ ë¶„ì„ ê²°ê³¼ ì„ íƒ
    table_analysis = (
        state["table_analysis"]
        if hallucination_reject_num == 0
        else state["revised_analysis"]
    )

    # âœ… í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = HALLUCINATION_CHECK_PROMPT.format(
        selected_question=state["selected_question"],
        linearized_table=state["linearized_table"],
        ft_test_summary=str(state["ft_test_summary"]),  # âœ… ì—¬ê¸°ì„œ ft_test_summary ì‚¬ìš©
        table_analysis=table_analysis
    )

    # âœ… LLM í˜¸ì¶œ
    with st.spinner("Hallucination í‰ê°€ ì¤‘..."):
        response = llm.invoke(prompt)

    result = response.content.strip()

    # âœ… ê²°ê³¼ í•´ì„ ë° ìƒíƒœ ì—…ë°ì´íŠ¸
    if result.lower().startswith("reject"):
        decision = "reject"
        feedback = result[len("reject"):].strip(": ").strip()
        hallucination_reject_num += 1
        st.warning(f"âŒ Hallucination Check ê²°ê³¼: {decision}")
        st.info(f"ğŸ’¡ LLM Feedback: {feedback}")
    else:
        decision = "accept"
        feedback = ""
        st.success(f"âœ… Hallucination Check ê²°ê³¼: {decision}")

    return {
        **state,
        "hallucination_check": decision,
        "feedback": feedback,
        "hallucination_reject_num": hallucination_reject_num
    }

# âœ… LangGraph ë…¸ë“œ ë“±ë¡
streamlit_hallucination_check_node = RunnableLambda(streamlit_hallucination_check_node_fn)