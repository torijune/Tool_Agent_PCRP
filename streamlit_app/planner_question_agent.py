from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI
import os
from dotenv import load_dotenv

load_dotenv()

llm = ChatOpenAI(temperature=0.3, model="gpt-4o-mini", openai_api_key=os.getenv("OPENAI_API_KEY"))

QUESTION_SUGGESTION_PROMPT = {
    "í•œêµ­ì–´": """
ë‹¹ì‹ ì€ ê³ ê¸‰ ì„¤ë¬¸ì¡°ì‚¬ ì„¤ê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì¡°ì‚¬ ì£¼ì œ, ëª©ì , íƒ€ê²Ÿ ì‘ë‹µì ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ë¯¸ ìˆëŠ” ì„¤ë¬¸ ë¬¸í•­ì„ ìƒì„±í•˜ì„¸ìš”.

ë‹¤ìŒì˜ Chain of Thoughtë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ë”°ë¼ê°€ë©° ì‚¬ê³ í•˜ê³  ì„¤ê³„í•˜ì„¸ìš”:

Step 1ï¸âƒ£: ì¡°ì‚¬ ëª©ì ì—ì„œ ì¸¡ì •í•˜ê³ ì í•˜ëŠ” í•µì‹¬ ê°œë… ë˜ëŠ” ë³€ìˆ˜ë“¤ì„ ì¶”ì¶œ  
Step 2ï¸âƒ£: íƒ€ê²Ÿ ì‘ë‹µìì˜ íŠ¹ì„±ì„ ê³ ë ¤í•˜ì—¬, ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ë¬¸í•­ì„ êµ¬ì„±í•´ì•¼ íš¨ê³¼ì ì¼ì§€ íŒë‹¨  
Step 3ï¸âƒ£: ê° í•µì‹¬ ê°œë…ì— ëŒ€ì‘í•˜ëŠ” êµ¬ì²´ì ì¸ ë¬¸í•­ì„ ì„¤ê³„í•˜ë˜, ê°€ëŠ¥í•œ í•œ ë‹¤ì–‘í•œ ì§ˆë¬¸ í˜•ì‹ì„ í™œìš© (ê°ê´€ì‹, 5ì  ì²™ë„, ì„œìˆ í˜• ë“±)  
Step 4ï¸âƒ£: ì¤‘ë³µ/í¸í–¥/ëª¨í˜¸í•œ ë¬¸í•­ì€ ì œê±°í•˜ê³ , ì „ì²´ íë¦„ì´ ìì—°ìŠ¤ëŸ½ë„ë¡ ì •ë ¬  
Step 5ï¸âƒ£: ê° ë¬¸í•­ ì˜†ì— (ë¬¸í•­ ëª©ì  ë° ìœ í˜•)ì„ ì£¼ì„ì²˜ëŸ¼ í•¨ê»˜ ê¸°ì…

ğŸ“Œ ì¡°ì‚¬ ì£¼ì œ: {topic}  
ğŸ“Œ ì¡°ì‚¬ ëª©ì : {generated_objective}  
ğŸ“Œ ì¡°ì‚¬ ì„¤ê³„: {structure}  
ğŸ“Œ íƒ€ê²Ÿ ì‘ë‹µì ì •ë³´: {audience}

---

âœï¸ ì„¤ê³„ëœ ë¬¸í•­ ëª©ë¡:
""",

    "English": """
You are an expert in survey methodology. Based on the topic, objective, and audience information below, generate thoughtful and research-aligned survey questions.

Please reason step-by-step using the following Chain of Thought:

Step 1ï¸âƒ£: Extract key constructs or variables based on the survey objective  
Step 2ï¸âƒ£: Consider how the target audience may interpret or respond to those constructs  
Step 3ï¸âƒ£: Create diverse question types (multiple choice, 5-point Likert, open-ended) for each construct  
Step 4ï¸âƒ£: Remove redundancy, bias, or vague wording, and ensure a logical progression of questions  
Step 5ï¸âƒ£: Annotate each question with its purpose and format in parentheses

ğŸ“Œ Topic: {topic}  
ğŸ“Œ Objective: {generated_objective}  
ğŸ“Œ Structure: {structure} 
ğŸ“Œ Target Audience: {audience}

---

âœï¸ Finalized Survey Questions:
"""
}

# âœ… LangGraph-compatible Node Function
def planner_question_agent_fn(state):
    topic = state["topic"]
    generated_objective = state["generated_objective"]
    audience = state["audience"]
    structure = state["structure"]
    lang = state.get("lang", "í•œêµ­ì–´")

    prompt = QUESTION_SUGGESTION_PROMPT[lang].format(
        topic=topic,
        generated_objective=generated_objective,
        audience=audience,
        structure=structure
    )
    response = llm.invoke(prompt)
    import streamlit as st
    st.markdown("### âœï¸ ì„¹ì…˜ë³„ ë¬¸í•­ ì œì•ˆ" if lang == "í•œêµ­ì–´" else "### âœï¸ Suggested Questions by Section")
    st.code(response.content.strip(), language="markdown")
    return {
        **state,
        "questions": response.content.strip()
    }

question_agent_node = RunnableLambda(planner_question_agent_fn)